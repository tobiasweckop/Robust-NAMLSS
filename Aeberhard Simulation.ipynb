{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAMLSS Code & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "\n",
    "class NormalNAMLSS(nn.Module):\n",
    "    def __init__(self, n_covariates, hidden_size=8, intercept=False):\n",
    "        super(NormalNAMLSS, self).__init__()\n",
    "\n",
    "        self.submodules = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1, hidden_size),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_size, 2)\n",
    "            ) for _ in range(n_covariates)\n",
    "        ])\n",
    "\n",
    "        self.use_intercept = intercept\n",
    "        if self.use_intercept:\n",
    "            self.intercept = nn.Parameter(torch.zeros(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        param_mat_list = [self.submodules[i](x[:, i:i + 1]) for i in range(x.shape[1])]\n",
    "        x = torch.stack(param_mat_list, dim=1)\n",
    "        mu_components = x[:, :, 0]\n",
    "        sigma_components = F.softplus(x[:, :, 1])\n",
    "\n",
    "        mu = torch.sum(mu_components, dim=1).unsqueeze(dim=1)\n",
    "        sigma = torch.sum(sigma_components, dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        if self.use_intercept:\n",
    "            mu = mu + self.intercept[0]\n",
    "            sigma = sigma + F.softplus(self.intercept[1])\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def nll_loss(self, mu, sigma, y_true, robustness_factor=None):\n",
    "        normal_dist = dist.Normal(mu, sigma)\n",
    "        # log_likelihood = normal_dist.log_prob(y_true).sum()\n",
    "        log_likelihood = normal_dist.log_prob(y_true).mean()\n",
    "\n",
    "        if robustness_factor is not None:\n",
    "            # log_likelihood = torch.log((1 + torch.exp(normal_dist.log_prob(y_true) + robustness_factor)) / (1 + torch.exp(robustness_factor))).sum()\n",
    "            log_likelihood = torch.log((1 + torch.exp(normal_dist.log_prob(y_true) + robustness_factor)) / (1 + torch.exp(robustness_factor))).mean()\n",
    "\n",
    "        nll = -log_likelihood\n",
    "        return nll\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, n_epochs=10000, lr=1e-3, weight_decay=0.0, \n",
    "            early_stopping_patience=10, robustness_factor=None):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            self.train()\n",
    "\n",
    "            # Forward pass and loss computation\n",
    "            mu, sigma = self.forward(X_train)\n",
    "            train_loss = self.nll_loss(mu, sigma, y_train, robustness_factor)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            val_loss = None\n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    mu_val, sigma_val = self.forward(X_val)\n",
    "                    val_loss = self.nll_loss(mu_val, sigma_val, y_val, robustness_factor).item()\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                    best_model_state = self.state_dict()\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if (patience_counter >= early_stopping_patience) and (epoch >= 1000):\n",
    "                    print(f\"Early stopping at epoch {epoch}. Best validation loss: {best_val_loss:.4f}\")\n",
    "                    self.load_state_dict(best_model_state)\n",
    "                    break\n",
    "\n",
    "            if epoch % 100 == 0 or val_loss is not None:\n",
    "                # print(f\"Epoch {epoch} - Train Loss: {train_loss.item():.4f} - Val Loss: {val_loss:.4f}\" if val_loss else f\"Epoch {epoch} - Train Loss: {train_loss.item():.4f}\")\n",
    "                pass\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        mu, sigma = self.forward(x)\n",
    "\n",
    "        mu = mu.detach()\n",
    "        sigma = sigma.detach()\n",
    "\n",
    "        return mu, sigma\n",
    "        \n",
    "\n",
    "    def marginal_effects(self, x):\n",
    "        with torch.no_grad():\n",
    "            param_mat_list = [self.submodules[i](x[:, i:i + 1]) for i in range(x.shape[1])]\n",
    "            x = torch.stack(param_mat_list, dim=1)\n",
    "            mu_components = x[:, :, 0].detach().cpu().numpy()\n",
    "            sigma_components = F.softplus(x[:, :, 1]).detach().cpu().numpy()\n",
    "        return mu_components, sigma_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(X):\n",
    "    return (2 * X + torch.sin(X * 2.5 * torch.pi)).squeeze()\n",
    "\n",
    "def F2(X):\n",
    "    return (3 - 3 * X ** 2).squeeze()\n",
    "\n",
    "def F3(X):\n",
    "    return (12 * (X - 0.5) ** 2).squeeze()\n",
    "\n",
    "def S1(X):\n",
    "    return torch.exp(-0.5 + 2 * X - 1.5 * X ** 2).squeeze()\n",
    "\n",
    "def S2(X):\n",
    "    return abs(1.2 - 1/2 * X).squeeze()\n",
    "\n",
    "def S3(X):\n",
    "    return (X/X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_gradient(z, c):\n",
    "    return np.exp(z + c)/(1 + np.exp(z + c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_aeberhard_penalty(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, target_mdp):\n",
    "\n",
    "    rob_vec = torch.tensor(list(np.arange(5, 0, -0.1)), dtype = torch.float32)\n",
    "    n_var = X_train_scaled.shape[1]\n",
    "    \n",
    "    prev_mdp = 0\n",
    "    best_rob = None\n",
    "\n",
    "    for rob in rob_vec:\n",
    "        prev_distance = abs(prev_mdp - target_mdp)\n",
    "        w_b_vector = []\n",
    "\n",
    "        candidate_model = NormalNAMLSS(n_var)\n",
    "        candidate_model.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = rob)\n",
    "        mu, sigma = candidate_model.predict(X_train_scaled)\n",
    "\n",
    "        normal_dist = dist.Normal(mu, sigma)\n",
    "\n",
    "        for _ in range(10):\n",
    "            y_b = torch.normal(mu, sigma)\n",
    "            ll = normal_dist.log_prob(y_b)\n",
    "            w_1b = rho_gradient(ll, rob)\n",
    "            w_b = torch.sum(w_1b) / len(y_b)\n",
    "            w_b_vector.append(w_b)\n",
    "\n",
    "        current_mdp = 1 - torch.median(torch.tensor(w_b_vector, dtype = torch.float32))\n",
    "        current_distance = abs(current_mdp - target_mdp)\n",
    "\n",
    "        if current_distance > prev_distance:\n",
    "            print(f\"stopping at {best_rob} --> mdp: {prev_mdp * 100}%\")\n",
    "            break\n",
    "\n",
    "        best_rob = rob\n",
    "        prev_mdp = current_mdp\n",
    "\n",
    "    return best_rob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation using 3 Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Corruption Proportions and corresponding aeberhard robustness settings at 5% and 10% MDP:\n",
    "- 0% --> 4.5, 3.6\n",
    "- 5% --> 4.3, 3.4\n",
    "- 10% --> 4.3, 3.2\n",
    "- 15% --> 4.3, 3.3\n",
    "- 20% --> 4.6, 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch.distributions as dist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def simulation_run(prop_corrupt, robust_c, strict_c):\n",
    "\n",
    "    ########## Drawing Covariate Samples ##########\n",
    "    n_train, n_val, n_test = 10000, 10000, 10000\n",
    "    n_var = 3\n",
    "    Uniform = dist.Uniform(0, 1)\n",
    "\n",
    "    X_train = Uniform.sample(sample_shape = [n_train, n_var])\n",
    "    X_val = Uniform.sample(sample_shape = [n_val, n_var])\n",
    "    X_test = Uniform.sample(sample_shape = [n_test, n_var])\n",
    "\n",
    "    ########## Training Dataset ##########\n",
    "    F1_train = F1(X_train[:,0])\n",
    "    F2_train = F2(X_train[:,1])\n",
    "    F3_train = F3(X_train[:,2])\n",
    "\n",
    "    S1_train = S1(X_train[:,0])\n",
    "    S2_train = S2(X_train[:,1])\n",
    "    S3_train = S3(X_train[:,2])\n",
    "\n",
    "    y_train = torch.normal(mean = F1_train + F2_train + F3_train, std = S1_train + S2_train + S3_train)\n",
    "    corrupted_train_indices = torch.tensor(random.sample(range(1, n_train), int(n_train * prop_corrupt)))\n",
    "    y_train[corrupted_train_indices] = torch.normal(torch.ones(len(corrupted_train_indices)) * 15, torch.ones(len(corrupted_train_indices)) * 2)\n",
    "    y_train = y_train.view(n_train, 1)\n",
    "\n",
    "    intact_train_indices = torch.ones(n_train, dtype=bool)\n",
    "    intact_train_indices[corrupted_train_indices] = False\n",
    "\n",
    "    ########## Validation Dataset ###########\n",
    "    F1_val = F1(X_val[:,0])\n",
    "    F2_val = F2(X_val[:,1])\n",
    "    F3_val = F3(X_val[:,2])\n",
    "\n",
    "    S1_val = S1(X_val[:,0])\n",
    "    S2_val = S2(X_val[:,1])\n",
    "    S3_val = S3(X_val[:,2])\n",
    "\n",
    "    y_val = torch.normal(mean = F1_val + F2_val + F3_val, std = S1_val + S2_val + S3_val)\n",
    "    corrupted_val_indices = torch.tensor(random.sample(range(1, n_val), int(n_val * prop_corrupt)))\n",
    "    y_val[corrupted_val_indices] = torch.normal(torch.ones(len(corrupted_val_indices)) * 15, torch.ones(len(corrupted_val_indices)) * 2)\n",
    "    y_val = y_val.view(n_val, 1)\n",
    "\n",
    "    intact_val_indices = torch.ones(n_test, dtype=bool)\n",
    "    intact_val_indices[corrupted_val_indices] = False\n",
    "\n",
    "    ########## Testing Dataset ##########\n",
    "    F1_test = F1(X_test[:,0])\n",
    "    F2_test = F2(X_test[:,1])\n",
    "    F3_test = F3(X_test[:,2])\n",
    "    F_test = np.column_stack((F1_test, F2_test, F3_test))\n",
    "\n",
    "    S1_test = S1(X_test[:,0])\n",
    "    S2_test = S2(X_test[:,1])\n",
    "    S3_test = S3(X_test[:,2])\n",
    "    S_test = np.column_stack((S1_test, S2_test, S3_test))\n",
    "\n",
    "    y_test = torch.normal(mean = F1_test + F2_test + F3_test, std = S1_test + S2_test + S3_test)\n",
    "    corrupted_test_indices = torch.tensor(random.sample(range(1, n_test), int(n_test * prop_corrupt)))\n",
    "    y_test[corrupted_test_indices] = torch.normal(torch.ones(len(corrupted_test_indices)) * 15, torch.ones(len(corrupted_test_indices)) * 2)\n",
    "\n",
    "    y_test = y_test.view(n_test, 1)\n",
    "\n",
    "    intact_test_indices = torch.ones(n_test, dtype=bool)\n",
    "    intact_test_indices[corrupted_test_indices] = False\n",
    "    \n",
    "    ########## Scaling the Data ##########\n",
    "    # scaler = StandardScaler()\n",
    "    # scaler1, scaler2, scaler3 = StandardScaler(), StandardScaler(), StandardScaler()\n",
    "\n",
    "    # X_train_scaled = torch.tensor(scaler.fit_transform(X_train[intact_train_indices]), dtype = torch.float32)\n",
    "    # X_val_scaled = torch.tensor(scaler.fit_transform(X_val), dtype = torch.float32)\n",
    "    # X_test_scaled = torch.tensor(scaler.fit_transform(X_test), dtype = torch.float32)\n",
    "\n",
    "    # y_train_scaled = torch.tensor(scaler1.fit_transform(y_train), dtype = torch.float32)\n",
    "    # y_val_scaled = torch.tensor(scaler2.fit_transform(y_val), dtype = torch.float32)\n",
    "    # y_test_scaled = torch.tensor(scaler3.fit_transform(y_test), dtype = torch.float32)\n",
    "\n",
    "    X_train_scaled = (X_train - torch.mean(X_train[intact_train_indices]))/torch.std(X_train[intact_train_indices])\n",
    "    X_val_scaled = (X_val - torch.mean(X_val[intact_val_indices]))/torch.std(X_val[intact_val_indices])\n",
    "    X_test_scaled = (X_test - torch.mean(X_test[intact_test_indices]))/torch.std(X_test[intact_test_indices])\n",
    "\n",
    "    y_train_scaled = (y_train - torch.mean(y_train[intact_train_indices]))/torch.std(y_train[intact_train_indices])\n",
    "    y_val_scaled = (y_val - torch.mean(y_val[intact_val_indices]))/torch.std(y_val[intact_val_indices])\n",
    "    y_test_scaled = (y_test - torch.mean(y_test[intact_test_indices]))/torch.std(y_test[intact_test_indices])\n",
    "\n",
    "    ########## Training the Networks ##########\n",
    "    nam = NormalNAMLSS(3)\n",
    "    nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = None)\n",
    "\n",
    "    # robust_c = get_aeberhard_penalty(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, 0.05)\n",
    "    # strict_c = get_aeberhard_penalty(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, 0.1)\n",
    "\n",
    "    robust_nam = NormalNAMLSS(3)\n",
    "    robust_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(robust_c))\n",
    "\n",
    "    strict_nam = NormalNAMLSS(3)\n",
    "    strict_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(strict_c))\n",
    "\n",
    "    ########## Predicting Parameters on Scaled Data ##########\n",
    "    mu, sigma = nam.predict(X_test_scaled)\n",
    "    rob_mu, rob_sigma = robust_nam.predict(X_test_scaled)\n",
    "    strict_mu, strict_sigma = strict_nam.predict(X_test_scaled)\n",
    "\n",
    "    mu_components, sigma_components = nam.marginal_effects(X_test_scaled)\n",
    "    robust_mu_components, robust_sigma_components = robust_nam.marginal_effects(X_test_scaled)\n",
    "    strict_mu_components, strict_sigma_components = strict_nam.marginal_effects(X_test_scaled)\n",
    "\n",
    "    ########## Calculating Loss on True Values only ##########\n",
    "    regular_loss = nam.nll_loss(mu[intact_test_indices], sigma[intact_test_indices], y_test_scaled[intact_test_indices]) * 1000\n",
    "    robust_loss = robust_nam.nll_loss(rob_mu[intact_test_indices], rob_sigma[intact_test_indices], y_test_scaled[intact_test_indices]) * 1000\n",
    "    strict_loss = strict_nam.nll_loss(strict_mu[intact_test_indices], strict_sigma[intact_test_indices], y_test_scaled[intact_test_indices]) * 1000\n",
    "\n",
    "    ########## MSE of predicted coefficients ##########\n",
    "\n",
    "\n",
    "    ########## Rescaling Predicted Parameters ##########\n",
    "    mu = mu * torch.std(y_test[intact_test_indices]) + torch.mean(y_test[intact_test_indices])\n",
    "    rob_mu = rob_mu * torch.std(y_test[intact_test_indices]) + torch.mean(y_test[intact_test_indices])\n",
    "    strict_mu = strict_mu * torch.std(y_test[intact_test_indices]) + torch.mean(y_test[intact_test_indices])\n",
    "\n",
    "    sigma = sigma * torch.std(y_test[intact_test_indices])\n",
    "    rob_sigma = rob_sigma * torch.std(y_test[intact_test_indices])\n",
    "    strict_sigma = strict_sigma * torch.std(y_test[intact_test_indices])\n",
    "\n",
    "    mu_components = mu_components * torch.std(y_test[intact_test_indices]).numpy() + torch.mean(y_test[intact_test_indices]).numpy()\n",
    "    robust_mu_components = robust_mu_components * torch.std(y_test[intact_test_indices]).numpy() + torch.mean(y_test[intact_test_indices]).numpy()\n",
    "    strict_mu_components = strict_mu_components * torch.std(y_test[intact_test_indices]).numpy() + torch.mean(y_test[intact_test_indices]).numpy()\n",
    "\n",
    "    sigma_components = sigma_components * torch.std(y_test[intact_test_indices]).numpy()\n",
    "    robust_sigma_components = robust_sigma_components * torch.std(y_test[intact_test_indices]).numpy()\n",
    "    strict_sigma_components = strict_sigma_components * torch.std(y_test[intact_test_indices]).numpy()\n",
    "\n",
    "    ########## Return Dictionary with Relevant Information ##########\n",
    "    run_result_dict = {\n",
    "        \"X_test\":X_test,\n",
    "        \"y_test\":y_test,\n",
    "        \"F_test\":F_test,\n",
    "        \"S_test\":S_test,\n",
    "        \"mu\":mu,\n",
    "        \"robust_mu\":rob_mu,\n",
    "        \"strict_mu\":strict_mu,\n",
    "        \"sigma\":sigma,\n",
    "        \"robust_sigma\":rob_sigma,\n",
    "        \"strict_sigma\":strict_sigma,\n",
    "        \"mu_components\": mu_components,\n",
    "        \"robust_mu_components\": robust_mu_components,\n",
    "        \"strict_mu_components\": strict_mu_components,\n",
    "        \"sigma_components\": sigma_components,\n",
    "        \"robust_sigma_components\": robust_sigma_components,\n",
    "        \"strict_sigma_components\": strict_sigma_components,\n",
    "        \"regular_loss\":regular_loss,\n",
    "        \"robust_loss\":robust_loss,\n",
    "        \"strict_loss\":strict_loss}\n",
    "    \n",
    "    return run_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(runs, prop_corrupt, rob_c, strict_c):\n",
    "    result_list = []\n",
    "    for i in range(runs):\n",
    "        print(f\"Running simulation {i+1}/{runs}\")\n",
    "        result_list.append(simulation_run(prop_corrupt, rob_c, strict_c))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_mse(simulation_run_dict):\n",
    "\n",
    "    F_test = simulation_run_dict[\"F_test\"]\n",
    "    mu_components = simulation_run_dict[\"mu_components\"]\n",
    "    robust_mu_components = simulation_run_dict[\"robust_mu_components\"]\n",
    "    strict_mu_components = simulation_run_dict[\"strict_mu_components\"]\n",
    "\n",
    "    S_test = simulation_run_dict[\"S_test\"]\n",
    "    sigma_components = simulation_run_dict[\"sigma_components\"]\n",
    "    robust_sigma_components = simulation_run_dict[\"robust_sigma_components\"]\n",
    "    strict_sigma_components = simulation_run_dict[\"strict_sigma_components\"] \n",
    "\n",
    "    # Mu\n",
    "    mean_mse_values = {\n",
    "        \"X1\": [\n",
    "            np.mean(((mu_components[:, 0] - mu_components[:, 0].mean()) - (F_test[:,0] - F_test[:,0].mean())) ** 2),\n",
    "            np.mean(((robust_mu_components[:, 0] - robust_mu_components[:, 0].mean()) - (F_test[:,0] - F_test[:,0].mean())) ** 2),\n",
    "            np.mean(((strict_mu_components[:, 0] - strict_mu_components[:, 0].mean()) - (F_test[:,0] - F_test[:,0].mean())) ** 2)\n",
    "        ],\n",
    "        \"X2\": [\n",
    "            np.mean(((mu_components[:, 1] - mu_components[:, 1].mean()) - (F_test[:,1] - F_test[:,1].mean())) ** 2),\n",
    "            np.mean(((robust_mu_components[:, 1] - robust_mu_components[:, 1].mean()) - (F_test[:,1] - F_test[:,1].mean())) ** 2),\n",
    "            np.mean(((strict_mu_components[:, 1] - strict_mu_components[:, 1].mean()) - (F_test[:,1] - F_test[:,1].mean())) ** 2)\n",
    "        ],\n",
    "        \"X3\": [\n",
    "            np.mean(((mu_components[:, 2] - mu_components[:, 2].mean()) - (F_test[:,2] - F_test[:,2].mean())) ** 2),\n",
    "            np.mean(((robust_mu_components[:, 2] - robust_mu_components[:, 2].mean()) - (F_test[:,2] - F_test[:,2].mean())) ** 2),\n",
    "            np.mean(((strict_mu_components[:, 2] - strict_mu_components[:, 2].mean()) - (F_test[:,2] - F_test[:,2].mean())) ** 2)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Sigma\n",
    "    sigma_mse_values = {\n",
    "        \"X1\": [\n",
    "            np.mean(((sigma_components[:, 0] - sigma_components[:, 0].mean()) - (S_test[:,0] - S_test[:,0].mean())) ** 2),\n",
    "            np.mean(((robust_sigma_components[:, 0] - robust_sigma_components[:, 0].mean()) - (S_test[:,0] - S_test[:,0].mean())) ** 2),\n",
    "            np.mean(((strict_sigma_components[:, 0] - strict_sigma_components[:, 0].mean()) - (S_test[:,0] - S_test[:,0].mean())) ** 2)\n",
    "        ],\n",
    "        \"X2\": [\n",
    "            np.mean(((sigma_components[:, 1] - sigma_components[:, 1].mean()) - (S_test[:,1] - S_test[:,1].mean())) ** 2),\n",
    "            np.mean(((robust_sigma_components[:, 1] - robust_sigma_components[:, 1].mean()) - (S_test[:,1] - S_test[:,1].mean())) ** 2),\n",
    "            np.mean(((strict_sigma_components[:, 1] - strict_sigma_components[:, 1].mean()) - (S_test[:,1] - S_test[:,1].mean())) ** 2)\n",
    "        ],\n",
    "        \"X3\": [\n",
    "            np.mean(((sigma_components[:, 2] - sigma_components[:, 2].mean()) - (S_test[:,2] - S_test[:,2].mean())) ** 2),\n",
    "            np.mean(((robust_sigma_components[:, 2] - robust_sigma_components[:, 2].mean()) - (S_test[:,2] - S_test[:,2].mean())) ** 2),\n",
    "            np.mean(((strict_sigma_components[:, 2] - strict_sigma_components[:, 2].mean()) - (S_test[:,2] - S_test[:,2].mean())) ** 2)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    mean_mse_df = pd.DataFrame(mean_mse_values, index=[\"mu\", \"robust_mu\", \"strict_mu\"]).round(5)\n",
    "    sigma_mse_df = pd.DataFrame(sigma_mse_values, index=[\"sigma\", \"robust_sigma\", \"strict_sigma\"]).round(5)\n",
    "\n",
    "    return {\"Mean_MSE\":mean_mse_df,\n",
    "            \"Sigma_MSE\":sigma_mse_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_mse_tables(simulation_runs):\n",
    "    mean_mse_list = []\n",
    "    sigma_mse_list = []\n",
    "    \n",
    "    for run_dict in simulation_runs:\n",
    "\n",
    "        mse_results = get_mse(run_dict)\n",
    "        \n",
    "        mean_mse_list.append(mse_results[\"Mean_MSE\"].values)\n",
    "        sigma_mse_list.append(mse_results[\"Sigma_MSE\"].values)\n",
    "    \n",
    "    mean_mse_array = np.array(mean_mse_list)  # Shape: (num_runs, 3, 3)\n",
    "    sigma_mse_array = np.array(sigma_mse_list)\n",
    "\n",
    "    # Compute averages across simulation runs\n",
    "    mean_mse_avg = np.mean(mean_mse_array, axis = 0)\n",
    "    sigma_mse_avg = np.mean(sigma_mse_array, axis = 0)\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    mean_mse_df = pd.DataFrame(mean_mse_avg, columns = [\"X1\", \"X2\", \"X3\"], index = [\"mu\", \"robust_mu\", \"strict_mu\"]).round(5)\n",
    "    sigma_mse_df = pd.DataFrame(sigma_mse_avg, columns = [\"X1\", \"X2\", \"X3\"], index = [\"sigma\", \"robust_sigma\", \"strict_sigma\"]).round(5)\n",
    "\n",
    "    return {\"Mean_MSE_Avg\": mean_mse_df, \"Sigma_MSE_Avg\": sigma_mse_df}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_effects(sim_list):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [20, 5])\n",
    "\n",
    "    average_mu_components = []\n",
    "    average_robust_mu_components = []\n",
    "    average_strict_mu_components = []\n",
    "\n",
    "    for element in sim_list:\n",
    "\n",
    "        X_test = element[\"X_test\"].numpy()\n",
    "        F_test = element[\"F_test\"]\n",
    "        mu_components = element[\"mu_components\"]\n",
    "        robust_mu_components = element[\"robust_mu_components\"]\n",
    "        strict_mu_components = element[\"strict_mu_components\"]\n",
    "\n",
    "        linestyle = (0, (3, 2))\n",
    "        linewidth1 = 2\n",
    "        linewidth2 = 1\n",
    "        alpha1 = 1\n",
    "        alpha2 = 0.1\n",
    "\n",
    "        true_color = \"deepskyblue\"\n",
    "        unregulated_color = \"#2ca02c\"\n",
    "        robust_color = \"indigo\"\n",
    "        strict_color = \"red\"\n",
    "\n",
    "        X_test_sorted = X_test.copy() # Warning: X_test_sorted is not useable as covariate matrix because the columns dont relate to each other after sorting!\n",
    "        F_test_sorted = F_test.copy()\n",
    "\n",
    "        mu_components_sorted = mu_components.copy()\n",
    "        robust_mu_components_sorted = robust_mu_components.copy()\n",
    "        strict_mu_components_sorted = strict_mu_components.copy()\n",
    "\n",
    "        average_mu_components.append(mu_components_sorted)\n",
    "        average_robust_mu_components.append(robust_mu_components_sorted)\n",
    "        average_strict_mu_components.append(strict_mu_components_sorted)\n",
    "\n",
    "        for variable in range(0,3):\n",
    "\n",
    "            sorted_indices = np.argsort(X_test[:,variable])\n",
    "            X_test_sorted[:, variable] = X_test[sorted_indices, variable]\n",
    "            F_test_sorted[:, variable] = F_test[sorted_indices, variable]\n",
    "\n",
    "            mu_components_sorted[:, variable] = mu_components[sorted_indices, variable]\n",
    "            robust_mu_components_sorted[:, variable] = robust_mu_components[sorted_indices, variable]\n",
    "            strict_mu_components_sorted[:, variable] = strict_mu_components[sorted_indices, variable]\n",
    "\n",
    "        for variable in range(0,3):\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (F_test_sorted[:,variable] - F_test_sorted[:,variable].mean()), color = true_color, linewidth = linewidth1, alpha = alpha1)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (mu_components_sorted[:,variable] - mu_components_sorted[:,variable].mean()), color = unregulated_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (robust_mu_components_sorted[:,variable] - robust_mu_components_sorted[:,variable].mean()), color = robust_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (strict_mu_components_sorted[:,variable] - strict_mu_components_sorted[:,variable].mean()), color = strict_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].set_title(\"True vs. Estimated Effect of X\" + str(variable + 1) + \" on Mean of Y\")\n",
    "            axes[variable].set_xlabel(\"X\" + str(variable + 1))\n",
    "            axes[variable].set_ylabel(\"E[Y]\")\n",
    "\n",
    "    average_mu_components = np.mean(np.array(average_mu_components), axis = 0)\n",
    "    average_robust_mu_components = np.mean(np.array(average_robust_mu_components), axis = 0)\n",
    "    average_strict_mu_components = np.mean(np.array(average_strict_mu_components), axis = 0)\n",
    "\n",
    "    for variable in range(0,3):\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_mu_components[:,variable] - average_mu_components[:,variable].mean(), color = unregulated_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_robust_mu_components[:,variable] - average_robust_mu_components[:,variable].mean(), color = robust_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_strict_mu_components[:,variable] - average_strict_mu_components[:,variable].mean(), color = strict_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        pass\n",
    "\n",
    "    axes[0].set_ylim([-1.6, 2.6])\n",
    "    axes[1].set_ylim([-2.1, 1.6])\n",
    "    axes[2].set_ylim([-1.1, 2.6])\n",
    "\n",
    "    legend_handles = [\n",
    "        plt.Line2D([0], [0], color=true_color, linewidth=linewidth1, label=\"True Effect\"),\n",
    "        plt.Line2D([0], [0], color=unregulated_color, linewidth=linewidth1, label=\"No Penalty\"),\n",
    "        plt.Line2D([0], [0], color=robust_color, linewidth=linewidth1, label=\"5% Penalty\"),\n",
    "        plt.Line2D([0], [0], color=strict_color, linewidth=linewidth1, label=\"10% Penalty\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "    axes[0].legend(handles = legend_handles, loc = \"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sigma_effects(sim_list):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [20, 5])\n",
    "    \n",
    "    linestyle = (0, (3, 2))\n",
    "    linewidth1 = 2\n",
    "    linewidth2 = 1\n",
    "    alpha1 = 1\n",
    "    alpha2 = 0.1\n",
    "\n",
    "    true_color = \"deepskyblue\"\n",
    "    unregulated_color = \"#2ca02c\"\n",
    "    robust_color = \"indigo\"\n",
    "    strict_color = \"red\"\n",
    "\n",
    "    average_sigma_components = []\n",
    "    average_robust_sigma_components = []\n",
    "    average_strict_sigma_components = []\n",
    "\n",
    "    for element in sim_list:\n",
    "\n",
    "        X_test = element[\"X_test\"].numpy()\n",
    "        S_test = element[\"S_test\"]\n",
    "        sigma_components = element[\"sigma_components\"]\n",
    "        robust_sigma_components = element[\"robust_sigma_components\"]\n",
    "        strict_sigma_components = element[\"strict_sigma_components\"] \n",
    "\n",
    "        X_test_sorted = X_test.copy() # Warning: X_test_sorted is not useable as covariate matrix because the columns dont relate to each other after sorting!\n",
    "        S_test_sorted = S_test.copy()\n",
    "\n",
    "        sigma_components_sorted = sigma_components.copy()\n",
    "        robust_sigma_components_sorted = robust_sigma_components.copy()\n",
    "        strict_sigma_components_sorted = strict_sigma_components.copy()\n",
    "\n",
    "        average_sigma_components.append(sigma_components_sorted)\n",
    "        average_robust_sigma_components.append(robust_sigma_components_sorted)\n",
    "        average_strict_sigma_components.append(strict_sigma_components_sorted)\n",
    "\n",
    "        for variable in range(0,3):\n",
    "\n",
    "            sorted_indices = np.argsort(X_test[:,variable])\n",
    "            X_test_sorted[:, variable] = X_test[sorted_indices, variable]\n",
    "            S_test_sorted[:, variable] = S_test[sorted_indices, variable]\n",
    "\n",
    "            sigma_components_sorted[:, variable] = sigma_components[sorted_indices, variable]\n",
    "            robust_sigma_components_sorted[:, variable] = robust_sigma_components[sorted_indices, variable]\n",
    "            strict_sigma_components_sorted[:, variable] = strict_sigma_components[sorted_indices, variable]\n",
    "\n",
    "        for variable in range(0,3):\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (S_test_sorted[:,variable] - S_test_sorted[:,variable].mean()), color = true_color, linewidth = linewidth1, alpha = alpha1)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (sigma_components_sorted[:,variable] - sigma_components_sorted[:,variable].mean()), color = unregulated_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (robust_sigma_components_sorted[:,variable] - robust_sigma_components_sorted[:,variable].mean()), color = robust_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (strict_sigma_components_sorted[:,variable] - strict_sigma_components_sorted[:,variable].mean()), color = strict_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].set_title(\"True vs. Estimated Effect of X\" + str(variable + 1) + \" on Var[Y]\")\n",
    "            axes[variable].set_xlabel(\"X\" + str(variable + 1))\n",
    "            axes[variable].set_ylabel(\"Var[Y]\")\n",
    "            axes[variable].set_ylim((-0.5,0.5))\n",
    "            \n",
    "    average_sigma_components = np.mean(np.array(average_sigma_components), axis = 0)\n",
    "    average_robust_sigma_components = np.mean(np.array(average_robust_sigma_components), axis = 0)\n",
    "    average_strict_sigma_components = np.mean(np.array(average_strict_sigma_components), axis = 0)\n",
    "\n",
    "    for variable in range(0,3):\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_sigma_components[:,variable] - average_sigma_components[:,variable].mean(), color = unregulated_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_robust_sigma_components[:,variable] - average_robust_sigma_components[:,variable].mean(), color = robust_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_strict_sigma_components[:,variable] - average_strict_sigma_components[:,variable].mean(), color = strict_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        pass\n",
    "\n",
    "    legend_handles = [\n",
    "        plt.Line2D([0], [0], color=true_color, linewidth=linewidth1, label=\"True Effect\"),\n",
    "        plt.Line2D([0], [0], color=unregulated_color, linewidth=linewidth1, label=\"No Penalty\"),\n",
    "        plt.Line2D([0], [0], color=robust_color, linewidth=linewidth1, label=\"5% Penalty\"),\n",
    "        plt.Line2D([0], [0], color=strict_color, linewidth=linewidth1, label=\"10% Penalty\"),\n",
    "    ]\n",
    "\n",
    "    axes[0].legend(handles = legend_handles, loc = \"upper left\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def get_true_value_loss(simulation_list):\n",
    "\n",
    "    # Extract losses and convert tensors to floats\n",
    "    loss_data = {\n",
    "        'regular_loss': [run['regular_loss'].item() for run in simulation_list],\n",
    "        'robust_loss': [run['robust_loss'].item() for run in simulation_list],\n",
    "        'strict_loss': [run['strict_loss'].item() for run in simulation_list]\n",
    "    }\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(loss_data)\n",
    "\n",
    "    # Compute mean and variance\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Mean': df.mean(),\n",
    "        'SD': df.std()\n",
    "    })\n",
    "\n",
    "    return round(summary_df, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def get_true_value_loss(simulation_list):\n",
    "    # Extract losses and convert tensors to floats\n",
    "    loss_data = {\n",
    "        'regular_loss': [run['regular_loss'].item() for run in simulation_list],\n",
    "        'robust_loss': [run['robust_loss'].item() for run in simulation_list],\n",
    "        'strict_loss': [run['strict_loss'].item() for run in simulation_list]\n",
    "    }\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(loss_data)\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    mean_values = df.mean()/10\n",
    "    std_values = df.std()/10\n",
    "\n",
    "    # Format output with standard deviation in parentheses\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Loss Summary': [f\"{mean:.2f} ({std:.2f})\" for mean, std in zip(mean_values, std_values)]\n",
    "    }, index=df.columns)\n",
    "\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list_0 = simulation(5, 0.001, 4.5, 3.6)\n",
    "sim_list_5 = simulation(5, 0.05, 4.3, 3.4)\n",
    "sim_list_10 = simulation(5, 0.10, 4.3, 3.2)\n",
    "sim_list_15 = simulation(5, 0.15, 4.3, 3.3)\n",
    "sim_list_20 = simulation(5, 0.20, 4.6, 3.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_true_value_loss(sim_list_0))\n",
    "print(get_true_value_loss(sim_list_5))\n",
    "print(get_true_value_loss(sim_list_10))\n",
    "print(get_true_value_loss(sim_list_15))\n",
    "print(get_true_value_loss(sim_list_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list_10 = simulation(20, 0.1, 4.3, 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_effects(sim_list_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = simulation_mse_tables(sim_list_10)\n",
    "table[\"Mean_MSE_Avg\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sigma_effects(sim_list_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"Sigma_MSE_Avg\"] * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
