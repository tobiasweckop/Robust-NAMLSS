{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAMLSS Code & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "\n",
    "class NormalNAMLSS(nn.Module):\n",
    "    def __init__(self, n_covariates, hidden_size=8, intercept=False):\n",
    "        super(NormalNAMLSS, self).__init__()\n",
    "\n",
    "        self.submodules = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1, hidden_size),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_size, 2)\n",
    "            ) for _ in range(n_covariates)\n",
    "        ])\n",
    "\n",
    "        self.use_intercept = intercept\n",
    "        if self.use_intercept:\n",
    "            self.intercept = nn.Parameter(torch.zeros(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        param_mat_list = [self.submodules[i](x[:, i:i + 1]) for i in range(x.shape[1])]\n",
    "        x = torch.stack(param_mat_list, dim=1)\n",
    "        mu_components = x[:, :, 0]\n",
    "        sigma_components = F.softplus(x[:, :, 1])\n",
    "\n",
    "        mu = torch.sum(mu_components, dim=1).unsqueeze(dim=1)\n",
    "        sigma = torch.sum(sigma_components, dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        if self.use_intercept:\n",
    "            mu = mu + self.intercept[0]\n",
    "            sigma = sigma + F.softplus(self.intercept[1])\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def nll_loss(self, mu, sigma, y_true, robustness_factor=None):\n",
    "        normal_dist = dist.Normal(mu, sigma)\n",
    "        log_likelihood = normal_dist.log_prob(y_true).mean()\n",
    "        # log_likelihood = normal_dist.log_prob(y_true).sum()\n",
    "\n",
    "        if robustness_factor is not None:\n",
    "            log_likelihood = torch.log((1 + torch.exp(normal_dist.log_prob(y_true) + robustness_factor)) / (1 + torch.exp(robustness_factor))).mean() \n",
    "            # log_likelihood = torch.log((1 + torch.exp(normal_dist.log_prob(y_true) + robustness_factor)) / (1 + torch.exp(robustness_factor))).sum()\n",
    "\n",
    "        nll = -log_likelihood\n",
    "        return nll\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, n_epochs=10000, lr=1e-3, weight_decay=0.0, \n",
    "            early_stopping_patience=10, robustness_factor=None):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            self.train()\n",
    "\n",
    "            # Forward pass and loss computation\n",
    "            mu, sigma = self.forward(X_train)\n",
    "            train_loss = self.nll_loss(mu, sigma, y_train, robustness_factor)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            val_loss = None\n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    mu_val, sigma_val = self.forward(X_val)\n",
    "                    val_loss = self.nll_loss(mu_val, sigma_val, y_val, robustness_factor).item()\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                    best_model_state = self.state_dict()\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if (patience_counter >= early_stopping_patience) and (epoch >= 1000):\n",
    "                    print(f\"Early stopping at epoch {epoch}. Best validation loss: {best_val_loss:.4f}\")\n",
    "                    self.load_state_dict(best_model_state)\n",
    "                    break\n",
    "\n",
    "            if epoch % 100 == 0 or val_loss is not None:\n",
    "                # print(f\"Epoch {epoch} - Train Loss: {train_loss.item():.4f} - Val Loss: {val_loss:.4f}\" if val_loss else f\"Epoch {epoch} - Train Loss: {train_loss.item():.4f}\")\n",
    "                pass\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        mu, sigma = self.forward(x)\n",
    "\n",
    "        mu = mu.detach()\n",
    "        sigma = sigma.detach()\n",
    "\n",
    "        return mu, sigma\n",
    "        \n",
    "\n",
    "    def marginal_effects(self, x):\n",
    "        with torch.no_grad():\n",
    "            param_mat_list = [self.submodules[i](x[:, i:i + 1]) for i in range(x.shape[1])]\n",
    "            x = torch.stack(param_mat_list, dim=1)\n",
    "            mu_components = x[:, :, 0].detach().cpu().numpy()\n",
    "            sigma_components = F.softplus(x[:, :, 1]).detach().cpu().numpy()\n",
    "        return mu_components, sigma_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(X):\n",
    "    return (2 * X + torch.sin(X * 2.5 * torch.pi)).squeeze()\n",
    "\n",
    "def F2(X):\n",
    "    return (3 - 3 * X ** 2).squeeze()\n",
    "\n",
    "def F3(X):\n",
    "    return (12 * (X - 0.5) ** 2).squeeze()\n",
    "\n",
    "def S1(X):\n",
    "    return torch.exp(-0.5 + 2 * X - 1.5 * X ** 2).squeeze()\n",
    "\n",
    "def S2(X):\n",
    "    return (1.2 - 1/2 * X).squeeze()\n",
    "\n",
    "def S3(X):\n",
    "    return (X/X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_gradient(z, c):\n",
    "    return np.exp(z + c)/(1 + np.exp(z + c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_aeberhard_penalty(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, target_mdp, verbose=False):\n",
    "\n",
    "    rob_vec = torch.tensor(list(np.arange(5, 0, -0.1)), dtype = torch.float32)\n",
    "    n_var = X_train_scaled.shape[1]\n",
    "    \n",
    "    prev_mdp = 0\n",
    "    best_rob = None\n",
    "\n",
    "    for rob in rob_vec:\n",
    "        prev_distance = abs(prev_mdp - target_mdp)\n",
    "        w_b_vector = []\n",
    "\n",
    "        candidate_model = NormalNAMLSS(n_var)\n",
    "        candidate_model.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = rob)\n",
    "        mu, sigma = candidate_model.predict(X_train_scaled)\n",
    "\n",
    "        normal_dist = dist.Normal(mu, sigma)\n",
    "\n",
    "        for _ in range(10):\n",
    "            y_b = torch.normal(mu, sigma)\n",
    "            ll = normal_dist.log_prob(y_b)\n",
    "            w_1b = rho_gradient(ll, rob)\n",
    "            w_b = torch.sum(w_1b) / len(y_b)\n",
    "            w_b_vector.append(w_b)\n",
    "\n",
    "        current_mdp = 1 - torch.median(torch.tensor(w_b_vector, dtype = torch.float32))\n",
    "        current_distance = abs(current_mdp - target_mdp)\n",
    "\n",
    "        if current_distance > prev_distance:\n",
    "            print(f\"stopping at {best_rob} --> mdp: {prev_mdp * 100}%\")\n",
    "            break\n",
    "\n",
    "        best_rob = rob\n",
    "        prev_mdp = current_mdp\n",
    "\n",
    "    return best_rob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation using 3 Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Corruption Proportions and corresponding aeberhard robustness settings at 5% and 10% MDP:\n",
    "- 0% --> 4.5, 3.6\n",
    "- 5% --> 4.3, 3.4\n",
    "- 10% --> 4.3, 3.2\n",
    "- 15% --> 4.3, 3.3\n",
    "- 20% --> 4.6, 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch.distributions as dist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def simulation_run(prop_corrupt, robust_c, strict_c):\n",
    "\n",
    "    ########## Drawing Covariate Samples ##########\n",
    "    n_train, n_val, n_test = 10000, 10000, 10000\n",
    "    n_var = 3\n",
    "    Uniform = dist.Uniform(0, 1)\n",
    "\n",
    "    X_train = Uniform.sample(sample_shape = [n_train, n_var])\n",
    "    X_val = Uniform.sample(sample_shape = [n_val, n_var])\n",
    "    X_test = Uniform.sample(sample_shape = [n_test, n_var])\n",
    "\n",
    "    ########## Training Dataset ##########\n",
    "    F1_train = F1(X_train[:,0])\n",
    "    F2_train = F2(X_train[:,1])\n",
    "    F3_train = F3(X_train[:,2])\n",
    "\n",
    "    S1_train = S1(X_train[:,0])\n",
    "    S2_train = S2(X_train[:,1])\n",
    "    S3_train = S3(X_train[:,2])\n",
    "\n",
    "    y_train = torch.normal(mean = F1_train + F2_train + F3_train, std = S1_train + S2_train + S3_train)\n",
    "    corrupted_train_indices = torch.tensor(random.sample(range(1, n_train), int(n_train * prop_corrupt)))\n",
    "    y_train[corrupted_train_indices] = torch.normal(torch.ones(len(corrupted_train_indices)) * 15, torch.ones(len(corrupted_train_indices)) * 2)\n",
    "    y_train = y_train.view(n_train, 1)\n",
    "\n",
    "    intact_train_indices = torch.ones(n_train, dtype=bool)\n",
    "    intact_train_indices[corrupted_train_indices] = False\n",
    "\n",
    "    ########## Validation Dataset ###########\n",
    "    F1_val = F1(X_val[:,0])\n",
    "    F2_val = F2(X_val[:,1])\n",
    "    F3_val = F3(X_val[:,2])\n",
    "\n",
    "    S1_val = S1(X_val[:,0])\n",
    "    S2_val = S2(X_val[:,1])\n",
    "    S3_val = S3(X_val[:,2])\n",
    "\n",
    "    y_val =  + torch.normal(mean = F1_val + F2_val + F3_val, std = S1_val + S2_val + S3_val)\n",
    "    corrupted_val_indices = torch.tensor(random.sample(range(1, n_val), int(n_val * prop_corrupt)))\n",
    "    y_val[corrupted_val_indices] = torch.normal(torch.ones(len(corrupted_val_indices)) * 15, torch.ones(len(corrupted_val_indices)) * 2)\n",
    "    y_val = y_val.view(n_val, 1)\n",
    "\n",
    "    ########## Testing Dataset ##########\n",
    "    F1_test = F1(X_test[:,0])\n",
    "    F2_test = F2(X_test[:,1])\n",
    "    F3_test = F3(X_test[:,2])\n",
    "    F_test = np.column_stack((F1_test, F2_test, F3_test))\n",
    "\n",
    "    S1_test = S1(X_test[:,0])\n",
    "    S2_test = S2(X_test[:,1])\n",
    "    S3_test = S3(X_test[:,2])\n",
    "    S_test = np.column_stack((S1_test, S2_test, S3_test))\n",
    "\n",
    "    y_test = torch.normal(mean = F1_test + F2_test + F3_test, std = S1_test + S2_test + S3_test)\n",
    "    corrupted_test_indices = torch.tensor(random.sample(range(1, n_test), int(n_test * prop_corrupt)))\n",
    "    y_test[corrupted_test_indices] = torch.normal(torch.ones(len(corrupted_test_indices)) * 15, torch.ones(len(corrupted_test_indices)) * 2)\n",
    "\n",
    "    y_test = y_test.view(n_test, 1)\n",
    "\n",
    "    intact_test_indices = torch.ones(n_test, dtype=bool)\n",
    "    intact_test_indices[corrupted_test_indices] = False\n",
    "    \n",
    "    ########## Scaling the Data ##########\n",
    "    scaler = StandardScaler()\n",
    "    scaler1, scaler2, scaler3 = StandardScaler(), StandardScaler(), StandardScaler()\n",
    "\n",
    "    X_train_scaled = torch.tensor(scaler.fit_transform(X_train), dtype = torch.float32)\n",
    "    X_val_scaled = torch.tensor(scaler.fit_transform(X_val), dtype = torch.float32)\n",
    "    X_test_scaled = torch.tensor(scaler.fit_transform(X_test), dtype = torch.float32)\n",
    "\n",
    "    y_train_scaled = torch.tensor(scaler1.fit_transform(y_train), dtype = torch.float32)\n",
    "    y_val_scaled = torch.tensor(scaler2.fit_transform(y_val), dtype = torch.float32)\n",
    "    y_test_scaled = torch.tensor(scaler3.fit_transform(y_test), dtype = torch.float32)\n",
    "\n",
    "    ########## Training the Networks ##########\n",
    "    nam = NormalNAMLSS(3)\n",
    "    nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = None)\n",
    "\n",
    "    # robust_c = get_aeberhard_penalty(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, 0.05)\n",
    "    # strict_c = get_aeberhard_penalty(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, 0.1)\n",
    "\n",
    "    robust_nam = NormalNAMLSS(3)\n",
    "    robust_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(robust_c))\n",
    "\n",
    "    strict_nam = NormalNAMLSS(3)\n",
    "    strict_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(strict_c))\n",
    "\n",
    "    ########## Predicting Parameters on Scaled Data ##########\n",
    "    mu, sigma = nam.predict(X_test_scaled)\n",
    "    rob_mu, rob_sigma = robust_nam.predict(X_test_scaled)\n",
    "    strict_mu, strict_sigma = strict_nam.predict(X_test_scaled)\n",
    "\n",
    "    mu_components, sigma_components = nam.marginal_effects(X_test_scaled)\n",
    "    robust_mu_components, robust_sigma_components = robust_nam.marginal_effects(X_test_scaled)\n",
    "    strict_mu_components, strict_sigma_components = strict_nam.marginal_effects(X_test_scaled)\n",
    "\n",
    "    ########## Calculating Loss on True Values only ##########\n",
    "    regular_loss = nam.nll_loss(mu[intact_test_indices], sigma[intact_test_indices], y_test_scaled[intact_test_indices]) * 10000\n",
    "    robust_loss = robust_nam.nll_loss(rob_mu[intact_test_indices], rob_sigma[intact_test_indices], y_test_scaled[intact_test_indices]) * 10000\n",
    "    strict_loss = strict_nam.nll_loss(strict_mu[intact_test_indices], strict_sigma[intact_test_indices], y_test_scaled[intact_test_indices]) * 10000\n",
    "\n",
    "    ########## Rescaling Predicted Parameters ##########\n",
    "    mu = mu * scaler3.scale_ + scaler3.mean_\n",
    "    rob_mu = rob_mu * scaler3.scale_ + scaler3.mean_\n",
    "    strict_mu = strict_mu * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "    sigma = sigma * scaler3.scale_\n",
    "    rob_sigma = rob_sigma * scaler3.scale_\n",
    "    strict_sigma = strict_sigma * scaler3.scale_\n",
    "\n",
    "    mu_components = mu_components * scaler3.scale_ + scaler3.mean_\n",
    "    robust_mu_components = robust_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "    strict_mu_components = strict_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "    sigma_components = sigma_components * scaler3.scale_\n",
    "    robust_sigma_components = robust_sigma_components * scaler3.scale_\n",
    "    strict_sigma_components = strict_sigma_components * scaler3.scale_\n",
    "\n",
    "    ########## Return Dictionary with Relevant Information ##########\n",
    "    run_result_dict = {\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"F_test\":F_test,\n",
    "        \"S_test\":S_test,\n",
    "        \"mu_components\": mu_components,\n",
    "        \"robust_mu_components\": robust_mu_components,\n",
    "        \"strict_mu_components\": strict_mu_components,\n",
    "        \"sigma_components\": sigma_components,\n",
    "        \"robust_sigma_components\": robust_sigma_components,\n",
    "        \"strict_sigma_components\": strict_sigma_components,\n",
    "        \"regular_loss\":regular_loss,\n",
    "        \"robust_loss\":robust_loss,\n",
    "        \"strict_loss\":strict_loss}\n",
    "    \n",
    "    return run_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(runs, prop_corrupt, rob_c, strict_c):\n",
    "    result_list = []\n",
    "    for i in range(runs):\n",
    "        print(f\"Running simulation {i+1}/{runs}\")\n",
    "        result_list.append(simulation_run(prop_corrupt, rob_c, strict_c))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_mse(simulation_run_dict):\n",
    "\n",
    "    F_test = simulation_run_dict[\"F_test\"]\n",
    "    mu_components = simulation_run_dict[\"mu_components\"]\n",
    "    robust_mu_components = simulation_run_dict[\"robust_mu_components\"]\n",
    "    strict_mu_components = simulation_run_dict[\"strict_mu_components\"]\n",
    "\n",
    "    S_test = simulation_run_dict[\"S_test\"]\n",
    "    sigma_components = simulation_run_dict[\"sigma_components\"]\n",
    "    robust_sigma_components = simulation_run_dict[\"robust_sigma_components\"]\n",
    "    strict_sigma_components = simulation_run_dict[\"strict_sigma_components\"] \n",
    "\n",
    "    # Mu\n",
    "    mean_mse_values = {\n",
    "        \"X1\": [\n",
    "            np.mean(((mu_components[:, 0] - mu_components[:, 0].mean()) - (F_test[:,0] - F_test[:,0].mean())) ** 2),\n",
    "            np.mean(((robust_mu_components[:, 0] - robust_mu_components[:, 0].mean()) - (F_test[:,0] - F_test[:,0].mean())) ** 2),\n",
    "            np.mean(((strict_mu_components[:, 0] - strict_mu_components[:, 0].mean()) - (F_test[:,0] - F_test[:,0].mean())) ** 2)\n",
    "        ],\n",
    "        \"X2\": [\n",
    "            np.mean(((mu_components[:, 1] - mu_components[:, 1].mean()) - (F_test[:,1] - F_test[:,1].mean())) ** 2),\n",
    "            np.mean(((robust_mu_components[:, 1] - robust_mu_components[:, 1].mean()) - (F_test[:,1] - F_test[:,1].mean())) ** 2),\n",
    "            np.mean(((strict_mu_components[:, 1] - strict_mu_components[:, 1].mean()) - (F_test[:,1] - F_test[:,1].mean())) ** 2)\n",
    "        ],\n",
    "        \"X3\": [\n",
    "            np.mean(((mu_components[:, 2] - mu_components[:, 2].mean()) - (F_test[:,2] - F_test[:,2].mean())) ** 2),\n",
    "            np.mean(((robust_mu_components[:, 2] - robust_mu_components[:, 2].mean()) - (F_test[:,2] - F_test[:,2].mean())) ** 2),\n",
    "            np.mean(((strict_mu_components[:, 2] - strict_mu_components[:, 2].mean()) - (F_test[:,2] - F_test[:,2].mean())) ** 2)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Sigma\n",
    "    sigma_mse_values = {\n",
    "        \"X1\": [\n",
    "            np.mean(((sigma_components[:, 0] - sigma_components[:, 0].mean()) - (S_test[:,0] - S_test[:,0].mean())) ** 2),\n",
    "            np.mean(((robust_sigma_components[:, 0] - robust_sigma_components[:, 0].mean()) - (S_test[:,0] - S_test[:,0].mean())) ** 2),\n",
    "            np.mean(((strict_sigma_components[:, 0] - strict_sigma_components[:, 0].mean()) - (S_test[:,0] - S_test[:,0].mean())) ** 2)\n",
    "        ],\n",
    "        \"X2\": [\n",
    "            np.mean(((sigma_components[:, 1] - sigma_components[:, 1].mean()) - (S_test[:,1] - S_test[:,1].mean())) ** 2),\n",
    "            np.mean(((robust_sigma_components[:, 1] - robust_sigma_components[:, 1].mean()) - (S_test[:,1] - S_test[:,1].mean())) ** 2),\n",
    "            np.mean(((strict_sigma_components[:, 1] - strict_sigma_components[:, 1].mean()) - (S_test[:,1] - S_test[:,1].mean())) ** 2)\n",
    "        ],\n",
    "        \"X3\": [\n",
    "            np.mean(((sigma_components[:, 2] - sigma_components[:, 2].mean()) - (S_test[:,2] - S_test[:,2].mean())) ** 2),\n",
    "            np.mean(((robust_sigma_components[:, 2] - robust_sigma_components[:, 2].mean()) - (S_test[:,2] - S_test[:,2].mean())) ** 2),\n",
    "            np.mean(((strict_sigma_components[:, 2] - strict_sigma_components[:, 2].mean()) - (S_test[:,2] - S_test[:,2].mean())) ** 2)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    mean_mse_df = pd.DataFrame(mean_mse_values, index=[\"mu\", \"robust_mu\", \"strict_mu\"]).round(5)\n",
    "    sigma_mse_df = pd.DataFrame(sigma_mse_values, index=[\"sigma\", \"robust_sigma\", \"strict_sigma\"]).round(5)\n",
    "\n",
    "    return {\"Mean_MSE\":mean_mse_df,\n",
    "            \"Sigma_MSE\":sigma_mse_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_mse_tables(simulation_runs):\n",
    "    mean_mse_list = []\n",
    "    sigma_mse_list = []\n",
    "    \n",
    "    for run_dict in simulation_runs:\n",
    "\n",
    "        mse_results = get_mse(run_dict)\n",
    "        \n",
    "        mean_mse_list.append(mse_results[\"Mean_MSE\"].values)\n",
    "        sigma_mse_list.append(mse_results[\"Sigma_MSE\"].values)\n",
    "    \n",
    "    mean_mse_array = np.array(mean_mse_list)  # Shape: (num_runs, 3, 3)\n",
    "    sigma_mse_array = np.array(sigma_mse_list)\n",
    "\n",
    "    # Compute averages across simulation runs\n",
    "    mean_mse_avg = np.mean(mean_mse_array, axis = 0)\n",
    "    sigma_mse_avg = np.mean(sigma_mse_array, axis = 0)\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    mean_mse_df = pd.DataFrame(mean_mse_avg, columns = [\"X1\", \"X2\", \"X3\"], index = [\"mu\", \"robust_mu\", \"strict_mu\"]).round(5)\n",
    "    sigma_mse_df = pd.DataFrame(sigma_mse_avg, columns = [\"X1\", \"X2\", \"X3\"], index = [\"sigma\", \"robust_sigma\", \"strict_sigma\"]).round(5)\n",
    "\n",
    "    return {\"Mean_MSE_Avg\": mean_mse_df, \"Sigma_MSE_Avg\": sigma_mse_df}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_effects(sim_list):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [20, 5])\n",
    "\n",
    "    average_mu_components = []\n",
    "    average_robust_mu_components = []\n",
    "    average_strict_mu_components = []\n",
    "\n",
    "    for element in sim_list:\n",
    "\n",
    "        X_test = element[\"X_test\"].numpy()\n",
    "        F_test = element[\"F_test\"]\n",
    "        mu_components = element[\"mu_components\"]\n",
    "        robust_mu_components = element[\"robust_mu_components\"]\n",
    "        strict_mu_components = element[\"strict_mu_components\"]\n",
    "\n",
    "        linestyle = (0, (3, 2))\n",
    "        linewidth1 = 2\n",
    "        linewidth2 = 1\n",
    "        alpha1 = 1\n",
    "        alpha2 = 0.1\n",
    "\n",
    "        true_color = \"deepskyblue\"\n",
    "        unregulated_color = \"#2ca02c\"\n",
    "        robust_color = \"indigo\"\n",
    "        strict_color = \"red\"\n",
    "\n",
    "        X_test_sorted = X_test.copy() # Warning: X_test_sorted is not useable as covariate matrix because the columns dont relate to each other after sorting!\n",
    "        F_test_sorted = F_test.copy()\n",
    "\n",
    "        mu_components_sorted = mu_components.copy()\n",
    "        robust_mu_components_sorted = robust_mu_components.copy()\n",
    "        strict_mu_components_sorted = strict_mu_components.copy()\n",
    "\n",
    "        average_mu_components.append(mu_components_sorted)\n",
    "        average_robust_mu_components.append(robust_mu_components_sorted)\n",
    "        average_strict_mu_components.append(strict_mu_components_sorted)\n",
    "\n",
    "        for variable in range(0,3):\n",
    "\n",
    "            sorted_indices = np.argsort(X_test[:,variable])\n",
    "            X_test_sorted[:, variable] = X_test[sorted_indices, variable]\n",
    "            F_test_sorted[:, variable] = F_test[sorted_indices, variable]\n",
    "\n",
    "            mu_components_sorted[:, variable] = mu_components[sorted_indices, variable]\n",
    "            robust_mu_components_sorted[:, variable] = robust_mu_components[sorted_indices, variable]\n",
    "            strict_mu_components_sorted[:, variable] = strict_mu_components[sorted_indices, variable]\n",
    "\n",
    "        for variable in range(0,3):\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (F_test_sorted[:,variable] - F_test_sorted[:,variable].mean()), color = true_color, linewidth = linewidth1, alpha = alpha1)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (mu_components_sorted[:,variable] - mu_components_sorted[:,variable].mean()), color = unregulated_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (robust_mu_components_sorted[:,variable] - robust_mu_components_sorted[:,variable].mean()), color = robust_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (strict_mu_components_sorted[:,variable] - strict_mu_components_sorted[:,variable].mean()), color = strict_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].set_title(\"True vs. Estimated Effect of X\" + str(variable + 1) + \" on Mean of Y\")\n",
    "            axes[variable].set_xlabel(\"X\" + str(variable + 1))\n",
    "            axes[variable].set_ylabel(\"E[Y]\")\n",
    "\n",
    "    average_mu_components = np.mean(np.array(average_mu_components), axis = 0)\n",
    "    average_robust_mu_components = np.mean(np.array(average_robust_mu_components), axis = 0)\n",
    "    average_strict_mu_components = np.mean(np.array(average_strict_mu_components), axis = 0)\n",
    "\n",
    "    for variable in range(0,3):\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_mu_components[:,variable] - average_mu_components[:,variable].mean(), color = unregulated_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_robust_mu_components[:,variable] - average_robust_mu_components[:,variable].mean(), color = robust_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_strict_mu_components[:,variable] - average_strict_mu_components[:,variable].mean(), color = strict_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        pass\n",
    "\n",
    "    axes[0].set_ylim([-1.6, 2.6])\n",
    "    axes[1].set_ylim([-2.1, 1.6])\n",
    "    axes[2].set_ylim([-1.1, 2.6])\n",
    "\n",
    "    legend_handles = [\n",
    "        plt.Line2D([0], [0], color=true_color, linewidth=linewidth1, label=\"True Effect\"),\n",
    "        plt.Line2D([0], [0], color=unregulated_color, linewidth=linewidth1, label=\"No Penalty\"),\n",
    "        plt.Line2D([0], [0], color=robust_color, linewidth=linewidth1, label=\"c = 3\"),\n",
    "        plt.Line2D([0], [0], color=strict_color, linewidth=linewidth1, label=\"c = 1\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "    axes[0].legend(handles = legend_handles, loc = \"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sigma_effects(sim_list):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [20, 5])\n",
    "    \n",
    "    linestyle = (0, (3, 2))\n",
    "    linewidth1 = 2\n",
    "    linewidth2 = 1\n",
    "    alpha1 = 1\n",
    "    alpha2 = 0.1\n",
    "\n",
    "    true_color = \"deepskyblue\"\n",
    "    unregulated_color = \"#2ca02c\"\n",
    "    robust_color = \"indigo\"\n",
    "    strict_color = \"red\"\n",
    "\n",
    "    average_sigma_components = []\n",
    "    average_robust_sigma_components = []\n",
    "    average_strict_sigma_components = []\n",
    "\n",
    "    for element in sim_list:\n",
    "\n",
    "        X_test = element[\"X_test\"].numpy()\n",
    "        S_test = element[\"S_test\"]\n",
    "        sigma_components = element[\"sigma_components\"]\n",
    "        robust_sigma_components = element[\"robust_sigma_components\"]\n",
    "        strict_sigma_components = element[\"strict_sigma_components\"] \n",
    "\n",
    "        X_test_sorted = X_test.copy() # Warning: X_test_sorted is not useable as covariate matrix because the columns dont relate to each other after sorting!\n",
    "        S_test_sorted = S_test.copy()\n",
    "\n",
    "        sigma_components_sorted = sigma_components.copy()\n",
    "        robust_sigma_components_sorted = robust_sigma_components.copy()\n",
    "        strict_sigma_components_sorted = strict_sigma_components.copy()\n",
    "\n",
    "        average_sigma_components.append(sigma_components_sorted)\n",
    "        average_robust_sigma_components.append(robust_sigma_components_sorted)\n",
    "        average_strict_sigma_components.append(strict_sigma_components_sorted)\n",
    "\n",
    "        for variable in range(0,3):\n",
    "\n",
    "            sorted_indices = np.argsort(X_test[:,variable])\n",
    "            X_test_sorted[:, variable] = X_test[sorted_indices, variable]\n",
    "            S_test_sorted[:, variable] = S_test[sorted_indices, variable]\n",
    "\n",
    "            sigma_components_sorted[:, variable] = sigma_components[sorted_indices, variable]\n",
    "            robust_sigma_components_sorted[:, variable] = robust_sigma_components[sorted_indices, variable]\n",
    "            strict_sigma_components_sorted[:, variable] = strict_sigma_components[sorted_indices, variable]\n",
    "\n",
    "        for variable in range(0,3):\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (S_test_sorted[:,variable] - S_test_sorted[:,variable].mean()), color = true_color, linewidth = linewidth1, alpha = alpha1)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (sigma_components_sorted[:,variable] - sigma_components_sorted[:,variable].mean()), color = unregulated_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (robust_sigma_components_sorted[:,variable] - robust_sigma_components_sorted[:,variable].mean()), color = robust_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].plot(X_test_sorted[:,variable], (strict_sigma_components_sorted[:,variable] - strict_sigma_components_sorted[:,variable].mean()), color = strict_color, linewidth = linewidth2, alpha = alpha2)\n",
    "            axes[variable].set_title(\"True vs. Estimated Effect of X\" + str(variable + 1) + \" on Var[Y]\")\n",
    "            axes[variable].set_xlabel(\"X\" + str(variable + 1))\n",
    "            axes[variable].set_ylabel(\"Var[Y]\")\n",
    "            axes[variable].set_ylim((-0.5,0.5))\n",
    "            \n",
    "    average_sigma_components = np.mean(np.array(average_sigma_components), axis = 0)\n",
    "    average_robust_sigma_components = np.mean(np.array(average_robust_sigma_components), axis = 0)\n",
    "    average_strict_sigma_components = np.mean(np.array(average_strict_sigma_components), axis = 0)\n",
    "\n",
    "    for variable in range(0,3):\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_sigma_components[:,variable] - average_sigma_components[:,variable].mean(), color = unregulated_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_robust_sigma_components[:,variable] - average_robust_sigma_components[:,variable].mean(), color = robust_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        axes[variable].plot(X_test_sorted[:,variable], average_strict_sigma_components[:,variable] - average_strict_sigma_components[:,variable].mean(), color = strict_color, linewidth = linewidth1, alpha = alpha1, linestyle = linestyle)\n",
    "        pass\n",
    "\n",
    "    legend_handles = [\n",
    "        plt.Line2D([0], [0], color=true_color, linewidth=linewidth1, label=\"True Effect\"),\n",
    "        plt.Line2D([0], [0], color=unregulated_color, linewidth=linewidth1, label=\"No Penalty\"),\n",
    "        plt.Line2D([0], [0], color=robust_color, linewidth=linewidth1, label=\"c = 3\"),\n",
    "        plt.Line2D([0], [0], color=strict_color, linewidth=linewidth1, label=\"c = 1\"),\n",
    "    ]\n",
    "\n",
    "    axes[0].legend(handles = legend_handles, loc = \"upper left\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def get_true_value_loss(simulation_list):\n",
    "\n",
    "    # Extract losses and convert tensors to floats\n",
    "    loss_data = {\n",
    "        'regular_loss': [run['regular_loss'].item() for run in simulation_list],\n",
    "        'robust_loss': [run['robust_loss'].item() for run in simulation_list],\n",
    "        'strict_loss': [run['strict_loss'].item() for run in simulation_list]\n",
    "    }\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(loss_data)\n",
    "\n",
    "    # Compute mean and variance\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Mean': df.mean(),\n",
    "        'SD': df.std()\n",
    "    })\n",
    "\n",
    "    print(round(summary_df, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation 1/20\n",
      "Early stopping at epoch 5697. Best validation loss: 13083.2656\n",
      "Early stopping at epoch 4671. Best validation loss: 12548.2393\n",
      "Early stopping at epoch 4854. Best validation loss: 11945.8535\n",
      "Running simulation 2/20\n",
      "Early stopping at epoch 2969. Best validation loss: 13061.6934\n",
      "Early stopping at epoch 3893. Best validation loss: 12490.6699\n",
      "Early stopping at epoch 4142. Best validation loss: 11904.3311\n",
      "Running simulation 3/20\n",
      "Early stopping at epoch 4674. Best validation loss: 13084.0420\n",
      "Early stopping at epoch 5741. Best validation loss: 12529.9893\n",
      "Early stopping at epoch 6964. Best validation loss: 11925.7920\n",
      "Running simulation 4/20\n",
      "Early stopping at epoch 2548. Best validation loss: 13049.3896\n",
      "Early stopping at epoch 2721. Best validation loss: 12519.0098\n",
      "Early stopping at epoch 3129. Best validation loss: 11928.3008\n",
      "Running simulation 5/20\n",
      "Early stopping at epoch 3879. Best validation loss: 13079.2822\n",
      "Early stopping at epoch 4686. Best validation loss: 12556.5781\n",
      "Early stopping at epoch 3726. Best validation loss: 11970.3340\n",
      "Running simulation 6/20\n",
      "Early stopping at epoch 6584. Best validation loss: 13018.5889\n",
      "Early stopping at epoch 5522. Best validation loss: 12482.7842\n",
      "Early stopping at epoch 2999. Best validation loss: 11892.2227\n",
      "Running simulation 7/20\n",
      "Early stopping at epoch 4504. Best validation loss: 13056.5156\n",
      "Early stopping at epoch 4974. Best validation loss: 12513.9238\n",
      "Early stopping at epoch 4299. Best validation loss: 11918.5645\n",
      "Running simulation 8/20\n",
      "Early stopping at epoch 3988. Best validation loss: 13113.2236\n",
      "Early stopping at epoch 5043. Best validation loss: 12551.7363\n",
      "Early stopping at epoch 5321. Best validation loss: 11946.3105\n",
      "Running simulation 9/20\n",
      "Early stopping at epoch 3796. Best validation loss: 13056.5908\n",
      "Early stopping at epoch 4394. Best validation loss: 12493.3555\n",
      "Early stopping at epoch 5053. Best validation loss: 11895.5176\n",
      "Running simulation 10/20\n",
      "Early stopping at epoch 3937. Best validation loss: 13087.8604\n",
      "Early stopping at epoch 4513. Best validation loss: 12554.6514\n",
      "Early stopping at epoch 4116. Best validation loss: 11959.9336\n",
      "Running simulation 11/20\n",
      "Early stopping at epoch 4737. Best validation loss: 13044.4775\n",
      "Early stopping at epoch 4544. Best validation loss: 12486.5586\n",
      "Early stopping at epoch 3238. Best validation loss: 11889.9355\n",
      "Running simulation 12/20\n",
      "Early stopping at epoch 7080. Best validation loss: 13104.3672\n",
      "Early stopping at epoch 7629. Best validation loss: 12551.9209\n",
      "Early stopping at epoch 6078. Best validation loss: 11956.0293\n",
      "Running simulation 13/20\n",
      "Early stopping at epoch 2414. Best validation loss: 13062.6914\n",
      "Early stopping at epoch 3312. Best validation loss: 12510.8594\n",
      "Early stopping at epoch 2292. Best validation loss: 11921.7764\n",
      "Running simulation 14/20\n",
      "Early stopping at epoch 4266. Best validation loss: 12993.8340\n",
      "Early stopping at epoch 3977. Best validation loss: 12475.0322\n",
      "Early stopping at epoch 5314. Best validation loss: 11882.6895\n",
      "Running simulation 15/20\n",
      "Early stopping at epoch 2712. Best validation loss: 13057.1475\n",
      "Early stopping at epoch 2728. Best validation loss: 12504.3203\n",
      "Early stopping at epoch 4500. Best validation loss: 11917.1387\n",
      "Running simulation 16/20\n",
      "Early stopping at epoch 2371. Best validation loss: 13020.3447\n",
      "Early stopping at epoch 4161. Best validation loss: 12498.1934\n",
      "Early stopping at epoch 4716. Best validation loss: 11918.9668\n",
      "Running simulation 17/20\n",
      "Early stopping at epoch 4947. Best validation loss: 12966.9805\n",
      "Early stopping at epoch 4249. Best validation loss: 12437.5664\n",
      "Early stopping at epoch 3421. Best validation loss: 11853.3682\n",
      "Running simulation 18/20\n",
      "Early stopping at epoch 2227. Best validation loss: 13064.1006\n",
      "Early stopping at epoch 1818. Best validation loss: 12521.9561\n",
      "Early stopping at epoch 2794. Best validation loss: 11919.1797\n",
      "Running simulation 19/20\n",
      "Early stopping at epoch 3697. Best validation loss: 13033.2764\n",
      "Early stopping at epoch 4328. Best validation loss: 12473.1348\n",
      "Early stopping at epoch 4583. Best validation loss: 11874.0791\n",
      "Running simulation 20/20\n",
      "Early stopping at epoch 2852. Best validation loss: 13100.5410\n",
      "Early stopping at epoch 4013. Best validation loss: 12565.4189\n",
      "Early stopping at epoch 4419. Best validation loss: 11960.8184\n",
      "Running simulation 1/20\n",
      "Early stopping at epoch 4865. Best validation loss: 13473.5195\n",
      "Early stopping at epoch 4119. Best validation loss: 12024.8418\n",
      "Early stopping at epoch 5180. Best validation loss: 11150.5977\n",
      "Running simulation 2/20\n",
      "Early stopping at epoch 4206. Best validation loss: 13538.9590\n",
      "Early stopping at epoch 4960. Best validation loss: 12062.7871\n",
      "Early stopping at epoch 4086. Best validation loss: 11166.5312\n",
      "Running simulation 3/20\n",
      "Early stopping at epoch 2382. Best validation loss: 13519.6064\n",
      "Early stopping at epoch 4219. Best validation loss: 12095.1289\n",
      "Early stopping at epoch 4178. Best validation loss: 11208.2979\n",
      "Running simulation 4/20\n",
      "Early stopping at epoch 2249. Best validation loss: 13480.7666\n",
      "Early stopping at epoch 3257. Best validation loss: 12008.6650\n",
      "Early stopping at epoch 3961. Best validation loss: 11105.7168\n",
      "Running simulation 5/20\n",
      "Early stopping at epoch 3906. Best validation loss: 13578.1719\n",
      "Early stopping at epoch 3771. Best validation loss: 12145.4238\n",
      "Early stopping at epoch 3189. Best validation loss: 11240.4756\n",
      "Running simulation 6/20\n",
      "Early stopping at epoch 3043. Best validation loss: 13516.0801\n",
      "Early stopping at epoch 4969. Best validation loss: 12098.9453\n",
      "Early stopping at epoch 3394. Best validation loss: 11213.0059\n",
      "Running simulation 7/20\n",
      "Early stopping at epoch 5387. Best validation loss: 13435.8252\n",
      "Early stopping at epoch 5577. Best validation loss: 12037.6514\n",
      "Early stopping at epoch 4302. Best validation loss: 11142.8184\n",
      "Running simulation 8/20\n",
      "Early stopping at epoch 3943. Best validation loss: 13547.2617\n",
      "Early stopping at epoch 5198. Best validation loss: 12152.1709\n",
      "Early stopping at epoch 4479. Best validation loss: 11269.3760\n",
      "Running simulation 9/20\n",
      "Early stopping at epoch 3181. Best validation loss: 13510.3955\n",
      "Early stopping at epoch 2254. Best validation loss: 12133.3477\n",
      "Early stopping at epoch 5671. Best validation loss: 11231.8145\n",
      "Running simulation 10/20\n",
      "Early stopping at epoch 3574. Best validation loss: 13451.5820\n",
      "Early stopping at epoch 5651. Best validation loss: 12029.2812\n",
      "Early stopping at epoch 3403. Best validation loss: 11150.0215\n",
      "Running simulation 11/20\n",
      "Early stopping at epoch 3922. Best validation loss: 13484.4668\n",
      "Early stopping at epoch 3443. Best validation loss: 12082.4434\n",
      "Early stopping at epoch 3157. Best validation loss: 11191.0166\n",
      "Running simulation 12/20\n",
      "Early stopping at epoch 3289. Best validation loss: 13513.8320\n",
      "Early stopping at epoch 2487. Best validation loss: 12088.6328\n",
      "Early stopping at epoch 5414. Best validation loss: 11180.1699\n",
      "Running simulation 13/20\n",
      "Early stopping at epoch 2916. Best validation loss: 13501.1631\n",
      "Early stopping at epoch 3809. Best validation loss: 12138.3936\n",
      "Early stopping at epoch 3957. Best validation loss: 11238.7930\n",
      "Running simulation 14/20\n",
      "Early stopping at epoch 4721. Best validation loss: 13456.6797\n",
      "Early stopping at epoch 2202. Best validation loss: 11971.8340\n",
      "Early stopping at epoch 3467. Best validation loss: 11071.1406\n",
      "Running simulation 15/20\n",
      "Early stopping at epoch 3355. Best validation loss: 13528.7559\n",
      "Early stopping at epoch 2627. Best validation loss: 12136.1279\n",
      "Early stopping at epoch 3647. Best validation loss: 11231.2520\n",
      "Running simulation 16/20\n",
      "Early stopping at epoch 2705. Best validation loss: 13531.6445\n",
      "Early stopping at epoch 4271. Best validation loss: 12010.2363\n",
      "Early stopping at epoch 1838. Best validation loss: 11104.6680\n",
      "Running simulation 17/20\n",
      "Early stopping at epoch 5304. Best validation loss: 13498.5527\n",
      "Early stopping at epoch 5957. Best validation loss: 12062.4697\n",
      "Early stopping at epoch 3547. Best validation loss: 11174.7969\n",
      "Running simulation 18/20\n",
      "Early stopping at epoch 5516. Best validation loss: 13437.5508\n",
      "Early stopping at epoch 5294. Best validation loss: 12039.1836\n",
      "Early stopping at epoch 3404. Best validation loss: 11158.9863\n",
      "Running simulation 19/20\n",
      "Early stopping at epoch 3700. Best validation loss: 13522.0762\n",
      "Early stopping at epoch 4545. Best validation loss: 12026.0225\n",
      "Early stopping at epoch 3738. Best validation loss: 11135.2871\n",
      "Running simulation 20/20\n",
      "Early stopping at epoch 2856. Best validation loss: 13538.6416\n",
      "Early stopping at epoch 6724. Best validation loss: 12070.2070\n",
      "Early stopping at epoch 5750. Best validation loss: 11187.0195\n",
      "Running simulation 1/20\n",
      "Early stopping at epoch 5611. Best validation loss: 13716.6084\n",
      "Early stopping at epoch 2762. Best validation loss: 12456.3574\n",
      "Early stopping at epoch 5150. Best validation loss: 11056.7207\n",
      "Running simulation 2/20\n",
      "Early stopping at epoch 5141. Best validation loss: 13696.4590\n",
      "Early stopping at epoch 1497. Best validation loss: 12429.2041\n",
      "Early stopping at epoch 5372. Best validation loss: 11042.9482\n",
      "Running simulation 3/20\n",
      "Early stopping at epoch 2064. Best validation loss: 13661.7930\n",
      "Early stopping at epoch 5481. Best validation loss: 12308.6260\n",
      "Early stopping at epoch 4590. Best validation loss: 10894.8516\n",
      "Running simulation 4/20\n",
      "Early stopping at epoch 4323. Best validation loss: 13670.7305\n",
      "Early stopping at epoch 3561. Best validation loss: 12447.9404\n",
      "Early stopping at epoch 5240. Best validation loss: 11066.1133\n",
      "Running simulation 5/20\n",
      "Early stopping at epoch 3614. Best validation loss: 13644.9453\n",
      "Early stopping at epoch 4717. Best validation loss: 12390.2568\n",
      "Early stopping at epoch 3409. Best validation loss: 10986.6309\n",
      "Running simulation 6/20\n",
      "Early stopping at epoch 2813. Best validation loss: 13640.7246\n",
      "Early stopping at epoch 3449. Best validation loss: 12330.8203\n",
      "Early stopping at epoch 2267. Best validation loss: 10933.2520\n",
      "Running simulation 7/20\n",
      "Early stopping at epoch 3477. Best validation loss: 13714.0654\n",
      "Early stopping at epoch 4537. Best validation loss: 12403.7246\n",
      "Early stopping at epoch 3213. Best validation loss: 10994.1367\n",
      "Running simulation 8/20\n",
      "Early stopping at epoch 4875. Best validation loss: 13730.9434\n",
      "Early stopping at epoch 3746. Best validation loss: 12422.1982\n",
      "Early stopping at epoch 5479. Best validation loss: 10987.9463\n",
      "Running simulation 9/20\n",
      "Early stopping at epoch 4522. Best validation loss: 13751.9238\n",
      "Early stopping at epoch 4376. Best validation loss: 12531.1816\n",
      "Early stopping at epoch 4698. Best validation loss: 11094.5996\n",
      "Running simulation 10/20\n",
      "Early stopping at epoch 1782. Best validation loss: 13686.4824\n",
      "Early stopping at epoch 6089. Best validation loss: 12435.9824\n",
      "Early stopping at epoch 3340. Best validation loss: 11050.0205\n",
      "Running simulation 11/20\n",
      "Early stopping at epoch 3111. Best validation loss: 13724.7773\n",
      "Early stopping at epoch 3342. Best validation loss: 12428.5293\n",
      "Early stopping at epoch 4973. Best validation loss: 10995.7217\n",
      "Running simulation 12/20\n",
      "Early stopping at epoch 4278. Best validation loss: 13702.8398\n",
      "Early stopping at epoch 1437. Best validation loss: 12361.8760\n",
      "Early stopping at epoch 1661. Best validation loss: 10936.7373\n",
      "Running simulation 13/20\n",
      "Early stopping at epoch 2706. Best validation loss: 13756.6562\n",
      "Early stopping at epoch 4447. Best validation loss: 12478.5430\n",
      "Early stopping at epoch 3676. Best validation loss: 11079.4355\n",
      "Running simulation 14/20\n",
      "Early stopping at epoch 3155. Best validation loss: 13738.3438\n",
      "Early stopping at epoch 3664. Best validation loss: 12459.1289\n",
      "Early stopping at epoch 5042. Best validation loss: 11030.4043\n",
      "Running simulation 15/20\n",
      "Early stopping at epoch 4290. Best validation loss: 13742.1201\n",
      "Early stopping at epoch 2754. Best validation loss: 12377.0957\n",
      "Early stopping at epoch 8231. Best validation loss: 10950.7129\n",
      "Running simulation 16/20\n",
      "Early stopping at epoch 3461. Best validation loss: 13680.5713\n",
      "Early stopping at epoch 5668. Best validation loss: 12410.9590\n",
      "Early stopping at epoch 4108. Best validation loss: 11017.0645\n",
      "Running simulation 17/20\n",
      "Early stopping at epoch 6026. Best validation loss: 13696.2783\n",
      "Early stopping at epoch 3347. Best validation loss: 12369.6621\n",
      "Early stopping at epoch 4379. Best validation loss: 10974.8008\n",
      "Running simulation 18/20\n",
      "Early stopping at epoch 4489. Best validation loss: 13667.3496\n",
      "Early stopping at epoch 3370. Best validation loss: 12366.5771\n",
      "Early stopping at epoch 3843. Best validation loss: 10989.1035\n",
      "Running simulation 19/20\n",
      "Early stopping at epoch 3919. Best validation loss: 13659.6865\n",
      "Early stopping at epoch 2914. Best validation loss: 12303.1758\n",
      "Early stopping at epoch 3452. Best validation loss: 10899.9688\n",
      "Running simulation 20/20\n",
      "Early stopping at epoch 6210. Best validation loss: 13665.1914\n",
      "Early stopping at epoch 1523. Best validation loss: 12424.4512\n",
      "Early stopping at epoch 2215. Best validation loss: 11030.2061\n",
      "Running simulation 1/20\n",
      "Early stopping at epoch 4378. Best validation loss: 13789.0840\n",
      "Early stopping at epoch 4241. Best validation loss: 12997.7109\n",
      "Early stopping at epoch 2369. Best validation loss: 11626.7939\n",
      "Running simulation 2/20\n",
      "Early stopping at epoch 4396. Best validation loss: 13792.8389\n",
      "Early stopping at epoch 1465. Best validation loss: 12957.0176\n",
      "Early stopping at epoch 2448. Best validation loss: 11542.0146\n",
      "Running simulation 3/20\n",
      "Early stopping at epoch 3406. Best validation loss: 13807.2861\n",
      "Early stopping at epoch 4186. Best validation loss: 13017.3535\n",
      "Early stopping at epoch 2750. Best validation loss: 11678.9658\n",
      "Running simulation 4/20\n",
      "Early stopping at epoch 3477. Best validation loss: 13843.2148\n",
      "Early stopping at epoch 5326. Best validation loss: 12997.3750\n",
      "Early stopping at epoch 2821. Best validation loss: 11644.5762\n",
      "Running simulation 5/20\n",
      "Early stopping at epoch 7312. Best validation loss: 13810.2793\n",
      "Early stopping at epoch 3839. Best validation loss: 13007.9326\n",
      "Early stopping at epoch 3150. Best validation loss: 11655.7080\n",
      "Running simulation 6/20\n",
      "Early stopping at epoch 3819. Best validation loss: 13797.9180\n",
      "Early stopping at epoch 4663. Best validation loss: 12949.9443\n",
      "Early stopping at epoch 5509. Best validation loss: 11607.6016\n",
      "Running simulation 7/20\n",
      "Early stopping at epoch 4188. Best validation loss: 13776.5801\n",
      "Early stopping at epoch 2298. Best validation loss: 12897.7900\n",
      "Early stopping at epoch 4012. Best validation loss: 11521.6230\n",
      "Running simulation 8/20\n",
      "Early stopping at epoch 4966. Best validation loss: 13805.6348\n",
      "Early stopping at epoch 2725. Best validation loss: 12952.7363\n",
      "Early stopping at epoch 4515. Best validation loss: 11581.9541\n",
      "Running simulation 9/20\n",
      "Early stopping at epoch 5839. Best validation loss: 13826.9434\n",
      "Early stopping at epoch 2270. Best validation loss: 13026.4121\n",
      "Early stopping at epoch 1469. Best validation loss: 11615.7891\n",
      "Running simulation 10/20\n",
      "Early stopping at epoch 5436. Best validation loss: 13832.2646\n",
      "Early stopping at epoch 3721. Best validation loss: 12995.0205\n",
      "Early stopping at epoch 5616. Best validation loss: 11604.1426\n",
      "Running simulation 11/20\n",
      "Early stopping at epoch 4284. Best validation loss: 13796.1211\n",
      "Early stopping at epoch 4988. Best validation loss: 12971.9541\n",
      "Early stopping at epoch 2750. Best validation loss: 11646.2246\n",
      "Running simulation 12/20\n",
      "Early stopping at epoch 4424. Best validation loss: 13788.9961\n",
      "Early stopping at epoch 4727. Best validation loss: 12927.1270\n",
      "Early stopping at epoch 1280. Best validation loss: 11578.1289\n",
      "Running simulation 13/20\n",
      "Early stopping at epoch 4191. Best validation loss: 13841.6660\n",
      "Early stopping at epoch 3724. Best validation loss: 12965.4053\n",
      "Early stopping at epoch 1211. Best validation loss: 11594.9053\n",
      "Running simulation 14/20\n",
      "Early stopping at epoch 3958. Best validation loss: 13784.5332\n",
      "Early stopping at epoch 3225. Best validation loss: 12902.8389\n",
      "Early stopping at epoch 4033. Best validation loss: 11524.2852\n",
      "Running simulation 15/20\n",
      "Early stopping at epoch 3126. Best validation loss: 13785.3311\n",
      "Early stopping at epoch 4810. Best validation loss: 12962.6680\n",
      "Early stopping at epoch 5754. Best validation loss: 11599.1436\n",
      "Running simulation 16/20\n",
      "Early stopping at epoch 3073. Best validation loss: 13791.8047\n",
      "Early stopping at epoch 4179. Best validation loss: 12901.5508\n",
      "Early stopping at epoch 3317. Best validation loss: 11560.9551\n",
      "Running simulation 17/20\n",
      "Early stopping at epoch 5385. Best validation loss: 13762.8135\n",
      "Early stopping at epoch 4328. Best validation loss: 12940.4678\n",
      "Early stopping at epoch 3696. Best validation loss: 11588.9102\n",
      "Running simulation 18/20\n",
      "Early stopping at epoch 4252. Best validation loss: 13801.9277\n",
      "Early stopping at epoch 5194. Best validation loss: 13016.7432\n",
      "Early stopping at epoch 3982. Best validation loss: 11656.7979\n",
      "Running simulation 19/20\n",
      "Early stopping at epoch 2344. Best validation loss: 13794.9629\n",
      "Early stopping at epoch 1681. Best validation loss: 12962.2119\n",
      "Early stopping at epoch 2023. Best validation loss: 11540.1553\n",
      "Running simulation 20/20\n",
      "Early stopping at epoch 2877. Best validation loss: 13811.0576\n",
      "Early stopping at epoch 3189. Best validation loss: 12961.7852\n",
      "Early stopping at epoch 2620. Best validation loss: 11627.5537\n",
      "Running simulation 1/20\n",
      "Early stopping at epoch 2467. Best validation loss: 13901.5527\n",
      "Early stopping at epoch 2945. Best validation loss: 13466.4238\n",
      "Early stopping at epoch 2578. Best validation loss: 12866.0293\n",
      "Running simulation 2/20\n",
      "Early stopping at epoch 2732. Best validation loss: 13888.6562\n",
      "Early stopping at epoch 4057. Best validation loss: 13458.2695\n",
      "Early stopping at epoch 2635. Best validation loss: 12831.3838\n",
      "Running simulation 3/20\n",
      "Early stopping at epoch 3674. Best validation loss: 13870.2031\n",
      "Early stopping at epoch 4853. Best validation loss: 13435.2139\n",
      "Early stopping at epoch 6318. Best validation loss: 12778.7422\n",
      "Running simulation 4/20\n",
      "Early stopping at epoch 4337. Best validation loss: 13873.1338\n",
      "Early stopping at epoch 4181. Best validation loss: 13444.0664\n",
      "Early stopping at epoch 5199. Best validation loss: 12851.2080\n",
      "Running simulation 5/20\n",
      "Early stopping at epoch 3117. Best validation loss: 13845.8242\n",
      "Early stopping at epoch 2742. Best validation loss: 13413.6123\n",
      "Early stopping at epoch 4422. Best validation loss: 12736.9521\n",
      "Running simulation 6/20\n",
      "Early stopping at epoch 3339. Best validation loss: 13854.2969\n",
      "Early stopping at epoch 2985. Best validation loss: 13421.9248\n",
      "Early stopping at epoch 5630. Best validation loss: 12753.5986\n",
      "Running simulation 7/20\n",
      "Early stopping at epoch 2963. Best validation loss: 13909.1611\n",
      "Early stopping at epoch 2530. Best validation loss: 13473.3066\n",
      "Early stopping at epoch 3260. Best validation loss: 12887.6250\n",
      "Running simulation 8/20\n",
      "Early stopping at epoch 6952. Best validation loss: 13837.7188\n",
      "Early stopping at epoch 5104. Best validation loss: 13396.7617\n",
      "Early stopping at epoch 2361. Best validation loss: 12725.4746\n",
      "Running simulation 9/20\n",
      "Early stopping at epoch 3475. Best validation loss: 13869.2754\n",
      "Early stopping at epoch 5771. Best validation loss: 13425.4150\n",
      "Early stopping at epoch 3651. Best validation loss: 12797.8643\n",
      "Running simulation 10/20\n",
      "Early stopping at epoch 4299. Best validation loss: 13878.1768\n",
      "Early stopping at epoch 3715. Best validation loss: 13441.1133\n",
      "Early stopping at epoch 3411. Best validation loss: 12762.4629\n",
      "Running simulation 11/20\n",
      "Early stopping at epoch 2671. Best validation loss: 13866.1504\n",
      "Early stopping at epoch 6004. Best validation loss: 13423.6455\n",
      "Early stopping at epoch 6344. Best validation loss: 12813.1592\n",
      "Running simulation 12/20\n",
      "Early stopping at epoch 5227. Best validation loss: 13833.0918\n",
      "Early stopping at epoch 5645. Best validation loss: 13392.7588\n",
      "Early stopping at epoch 2651. Best validation loss: 12708.0684\n",
      "Running simulation 13/20\n",
      "Early stopping at epoch 3035. Best validation loss: 13841.0068\n",
      "Early stopping at epoch 3914. Best validation loss: 13402.1797\n",
      "Early stopping at epoch 2669. Best validation loss: 12711.1318\n",
      "Running simulation 14/20\n",
      "Early stopping at epoch 5827. Best validation loss: 13848.2588\n",
      "Early stopping at epoch 4524. Best validation loss: 13419.1836\n",
      "Early stopping at epoch 2544. Best validation loss: 12837.4912\n",
      "Running simulation 15/20\n",
      "Early stopping at epoch 4101. Best validation loss: 13884.1533\n",
      "Early stopping at epoch 4013. Best validation loss: 13452.2578\n",
      "Early stopping at epoch 1000. Best validation loss: 12888.6270\n",
      "Running simulation 16/20\n",
      "Early stopping at epoch 4552. Best validation loss: 13862.2734\n",
      "Early stopping at epoch 5051. Best validation loss: 13427.1777\n",
      "Early stopping at epoch 2640. Best validation loss: 12814.9492\n",
      "Running simulation 17/20\n",
      "Early stopping at epoch 4416. Best validation loss: 13857.5781\n",
      "Early stopping at epoch 4536. Best validation loss: 13430.3955\n",
      "Early stopping at epoch 3912. Best validation loss: 12826.4082\n",
      "Running simulation 18/20\n",
      "Early stopping at epoch 5720. Best validation loss: 13849.7197\n",
      "Early stopping at epoch 2691. Best validation loss: 13424.7080\n",
      "Early stopping at epoch 2249. Best validation loss: 12822.9727\n",
      "Running simulation 19/20\n",
      "Early stopping at epoch 2451. Best validation loss: 13864.5713\n",
      "Early stopping at epoch 2448. Best validation loss: 13430.9414\n",
      "Early stopping at epoch 2619. Best validation loss: 12773.8496\n",
      "Running simulation 20/20\n",
      "Early stopping at epoch 4053. Best validation loss: 13839.4805\n",
      "Early stopping at epoch 5496. Best validation loss: 13402.4258\n",
      "Early stopping at epoch 1718. Best validation loss: 12721.5078\n"
     ]
    }
   ],
   "source": [
    "sim_list_0 = simulation(20, 0.001, 4.5, 3.6)\n",
    "sim_list_5 = simulation(20, 0.05, 4.3, 3.4)\n",
    "sim_list_10 = simulation(20, 0.10, 4.3, 3.2)\n",
    "sim_list_15 = simulation(20, 0.15, 4.3, 3.3)\n",
    "sim_list_20 = simulation(20, 0.20, 4.6, 3.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Mean      SD\n",
      "regular_loss  9136.26   23.51\n",
      "robust_loss   8835.38   32.50\n",
      "strict_loss   7741.83  285.92\n"
     ]
    }
   ],
   "source": [
    "get_true_value_loss(sim_list_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_mean_effects(simulation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = simulation_mse_tables(simulation_list)\n",
    "# table[\"Mean_MSE_Avg\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_sigma_effects(simulation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table[\"Sigma_MSE_Avg\"] * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
