{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcasing the Effect of NAMLSS-Robustification using a one-dimensional Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAMLSS Code & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "\n",
    "class NormalNAMLSS(nn.Module):\n",
    "    def __init__(self, n_covariates, hidden_size=8, intercept=False):\n",
    "        super(NormalNAMLSS, self).__init__()\n",
    "\n",
    "        self.submodules = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1, hidden_size),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_size, 2)\n",
    "            ) for _ in range(n_covariates)\n",
    "        ])\n",
    "\n",
    "        self.use_intercept = intercept\n",
    "        if self.use_intercept:\n",
    "            self.intercept = nn.Parameter(torch.zeros(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        param_mat_list = [self.submodules[i](x[:, i:i + 1]) for i in range(x.shape[1])]\n",
    "        x = torch.stack(param_mat_list, dim=1)\n",
    "        mu_components = x[:, :, 0]\n",
    "        sigma_components = F.softplus(x[:, :, 1])\n",
    "\n",
    "        mu = torch.sum(mu_components, dim=1).unsqueeze(dim=1)\n",
    "        sigma = torch.sum(sigma_components, dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        if self.use_intercept:\n",
    "            mu = mu + self.intercept[0]\n",
    "            sigma = sigma + F.softplus(self.intercept[1])\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def nll_loss(self, mu, sigma, y_true, robustness_factor=None):\n",
    "        normal_dist = dist.Normal(mu, sigma)\n",
    "        log_likelihood = normal_dist.log_prob(y_true).mean()\n",
    "\n",
    "        if robustness_factor is not None:\n",
    "            log_likelihood = torch.log((1 + torch.exp(normal_dist.log_prob(y_true) + robustness_factor)) / (1 + torch.exp(robustness_factor))).mean() \n",
    "\n",
    "        nll = -log_likelihood\n",
    "        return nll\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, n_epochs=10000, lr=1e-3, weight_decay=0.0, \n",
    "            early_stopping_patience=10, robustness_factor=None):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            self.train()\n",
    "\n",
    "            # Forward pass and loss computation\n",
    "            mu, sigma = self.forward(X_train)\n",
    "            train_loss = self.nll_loss(mu, sigma, y_train, robustness_factor)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            val_loss = None\n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    mu_val, sigma_val = self.forward(X_val)\n",
    "                    val_loss = self.nll_loss(mu_val, sigma_val, y_val, robustness_factor).item()\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                    best_model_state = self.state_dict()\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if (patience_counter >= early_stopping_patience) and (epoch >= 1000):\n",
    "                    print(f\"Early stopping at epoch {epoch}. Best validation loss: {best_val_loss:.4f}\")\n",
    "                    self.load_state_dict(best_model_state)\n",
    "                    break\n",
    "\n",
    "            if epoch % 100 == 0 or val_loss is not None:\n",
    "                # print(f\"Epoch {epoch} - Train Loss: {train_loss.item():.4f} - Val Loss: {val_loss:.4f}\" if val_loss else f\"Epoch {epoch} - Train Loss: {train_loss.item():.4f}\")\n",
    "                pass\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        mu, sigma = self.forward(x)\n",
    "\n",
    "        mu = mu.detach()\n",
    "        sigma = sigma.detach()\n",
    "\n",
    "        return mu, sigma\n",
    "        \n",
    "\n",
    "    def marginal_effects(self, x):\n",
    "        with torch.no_grad():\n",
    "            param_mat_list = [self.submodules[i](x[:, i:i + 1]) for i in range(x.shape[1])]\n",
    "            x = torch.stack(param_mat_list, dim=1)\n",
    "            mu_components = x[:, :, 0].detach().cpu().numpy()\n",
    "            sigma_components = F.softplus(x[:, :, 1]).detach().cpu().numpy()\n",
    "        return mu_components, sigma_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(X):\n",
    "    return (2 * X + torch.sin(X * 2.5 * torch.pi)).squeeze()\n",
    "\n",
    "def F2(X):\n",
    "    return (3 - 3 * X ** 2).squeeze()\n",
    "\n",
    "def F3(X):\n",
    "    return (12 * (X - 0.5) ** 2).squeeze()\n",
    "\n",
    "def S1(X):\n",
    "    return torch.exp(-0.5 + 2 * X - 1.5 * X ** 2).squeeze()\n",
    "\n",
    "def S2(X):\n",
    "    return (1.2 - 1/2 * X).squeeze()\n",
    "\n",
    "def S3(X):\n",
    "    return (X/X).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check: Data with no Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(X):\n",
    "    return (2 * X + torch.sin(X * 2.5 * torch.pi)).squeeze()\n",
    "\n",
    "def S1(X):\n",
    "    return torch.exp(-0.5 + 2 * X - 1.5 * X ** 2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "\n",
    "########## Drawing Covariate Samples ##########\n",
    "n_train, n_val, n_test = 10000, 10000, 10000\n",
    "Uniform = dist.Uniform(0, 1)\n",
    "\n",
    "X_train = Uniform.sample(sample_shape = [n_train, 1])\n",
    "X_val = Uniform.sample(sample_shape = [n_val, 1])\n",
    "X_test = Uniform.sample(sample_shape = [n_test, 1])\n",
    "\n",
    "########## Training Dataset ##########\n",
    "F1_train = F1(X_train)\n",
    "S1_train = S1(X_train)\n",
    "\n",
    "y_train = F1_train + torch.normal(mean=torch.zeros(n_train), std = S1_train)\n",
    "y_train = y_train.view(n_train, 1)\n",
    "\n",
    "########## Validation Dataset ###########\n",
    "F1_val = F1(X_val)\n",
    "S1_val = S1(X_val)\n",
    "\n",
    "y_val = F1_val + torch.normal(torch.zeros(n_val), std = S1_val)\n",
    "y_val = y_val.view(n_val, 1)\n",
    "\n",
    "########## Testing Dataset ##########\n",
    "F1_test = F1(X_test)\n",
    "S1_test = S1(X_test)\n",
    "\n",
    "y_test = F1_test + torch.normal(torch.zeros(n_test), std = S1_test)\n",
    "y_test = y_test.view(n_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "########## Plotting the Data ##########\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
    "\n",
    "axes[0].plot(X_test, y_test, \"o\", markersize = 2)\n",
    "axes[0].set_title(\"Scatterplot of X and Y\")\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"Y\")\n",
    "\n",
    "axes[1].plot(X_test, F1_test, \"o\", markersize = 2)\n",
    "axes[1].set_title(\"Relationship between X and E[Y]\")\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"E[Y]\")\n",
    "\n",
    "axes[2].plot(X_test, S1_test, \"o\", markersize = 2)\n",
    "axes[2].set_title(\"Relationship between X and Var[Y]\")\n",
    "axes[2].set_xlabel(\"X\")\n",
    "axes[2].set_ylabel(\"Var[Y]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler1, scaler2, scaler3 = StandardScaler(), StandardScaler(), StandardScaler()\n",
    "\n",
    "X_train_scaled = torch.tensor(scaler.fit_transform(X_train), dtype = torch.float32)\n",
    "X_val_scaled = torch.tensor(scaler.fit_transform(X_val), dtype = torch.float32)\n",
    "X_test_scaled = torch.tensor(scaler.fit_transform(X_test), dtype = torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(scaler1.fit_transform(y_train), dtype = torch.float32)\n",
    "y_val_scaled = torch.tensor(scaler2.fit_transform(y_val), dtype = torch.float32)\n",
    "y_test_scaled = torch.tensor(scaler3.fit_transform(y_test), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = NormalNAMLSS(1)\n",
    "nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_nam = NormalNAMLSS(1)\n",
    "robust_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_nam = NormalNAMLSS(1)\n",
    "strict_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Predicting Parameters on scaled data ##########\n",
    "mu, sigma = nam.predict(X_test_scaled)\n",
    "rob_mu, rob_sigma = robust_nam.predict(X_test_scaled)\n",
    "strict_mu, strict_sigma = strict_nam.predict(X_test_scaled)\n",
    "\n",
    "mu_components, sigma_components = nam.marginal_effects(X_test_scaled)\n",
    "robust_mu_components, robust_sigma_components = robust_nam.marginal_effects(X_test_scaled)\n",
    "strict_mu_components, strict_sigma_components = strict_nam.marginal_effects(X_test_scaled)\n",
    "\n",
    "########## Rescaling predicted parameters ##########\n",
    "mu = mu * scaler3.scale_ + scaler3.mean_\n",
    "rob_mu = rob_mu * scaler3.scale_ + scaler3.mean_\n",
    "strict_mu = strict_mu * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "sigma = sigma * scaler3.scale_\n",
    "rob_sigma = rob_sigma * scaler3.scale_\n",
    "strict_sigma = strict_sigma * scaler3.scale_\n",
    "\n",
    "mu_components = mu_components * scaler3.scale_ + scaler3.mean_\n",
    "robust_mu_components = robust_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "strict_mu_components = strict_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "sigma_components = sigma_components * scaler3.scale_\n",
    "robust_sigma_components = robust_sigma_components * scaler3.scale_\n",
    "strict_sigma_components = strict_sigma_components * scaler3.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Predicted Quantiles ##########\n",
    "lower = mu - 1.96 * sigma\n",
    "upper = mu + 1.96 * sigma\n",
    "\n",
    "robust_lower = rob_mu - 1.96 * rob_sigma\n",
    "robust_upper = rob_mu + 1.96 * rob_sigma\n",
    "\n",
    "strict_lower = strict_mu - 1.96 * strict_sigma\n",
    "strict_upper = strict_mu + 1.96 * strict_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize = 3\n",
    "alpha = 0.4\n",
    "\n",
    "true_color = \"C0\"\n",
    "unregulated_color = \"C2\"\n",
    "robust_color = \"orange\"\n",
    "strict_color = \"tomato\"\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [20, 5])\n",
    "\n",
    "axes[0].plot(X_test, F1_test, \"o\", color = true_color, markersize = markersize)\n",
    "axes[0].plot(X_test, mu, \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[0].plot(X_test, rob_mu, \"o\", color = robust_color, markersize = markersize)\n",
    "axes[0].plot(X_test, strict_mu, \"o\", color = strict_color, markersize = markersize)\n",
    "axes[0].set_title(\"Unstandardized Estimated Mean Curves\")\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"E[Y]\")\n",
    "\n",
    "axes[1].plot(X_test, F1_test - F1_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[1].plot(X_test, mu - mu.mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[1].plot(X_test, rob_mu - rob_mu.mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "axes[1].plot(X_test, strict_mu - strict_mu.mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[1].set_title(\"Standardized Estimated Mean Curves\")\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"E[Y]\")\n",
    "\n",
    "axes[2].plot(X_test, y_test, \"o\", color = true_color, markersize = 2)\n",
    "axes[2].plot(X_test, lower, \"o\", color = unregulated_color, markersize = 2)\n",
    "axes[2].plot(X_test, upper, \"o\", color = unregulated_color, markersize = 2)\n",
    "axes[2].plot(X_test, robust_lower, \"o\", color = robust_color, markersize = 2)\n",
    "axes[2].plot(X_test, robust_upper, \"o\", color = robust_color, markersize = 2)\n",
    "axes[2].plot(X_test, strict_lower, \"o\", color = strict_color, markersize = 2)\n",
    "axes[2].plot(X_test, strict_upper, \"o\", color = strict_color, markersize = 2)\n",
    "axes[2].set_title(\"Estimated 95% Coverage Intervals\")\n",
    "axes[2].set_xlabel(\"X\")\n",
    "axes[2].set_ylabel(\"Y\")\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=true_color, linewidth=markersize, label=\"True Effect\"),\n",
    "    plt.Line2D([0], [0], color=unregulated_color, linewidth=markersize, label=\"No Penalty\"),\n",
    "    plt.Line2D([0], [0], color=robust_color, linewidth=markersize, label=\"c = 3\"),\n",
    "    plt.Line2D([0], [0], color=strict_color, linewidth=markersize, label=\"c = 1\"),\n",
    "]\n",
    "\n",
    "# for variable in range(3):\n",
    "#     axes[variable].legend(handles=legend_handles, loc=\"best\")\n",
    "\n",
    "axes[0].legend(handles = legend_handles, loc = \"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = [16, 5])\n",
    "\n",
    "axes[0].plot(X_test, S1_test, \"o\", color = true_color, markersize = markersize)\n",
    "axes[0].plot(X_test, sigma, \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[0].plot(X_test, robust_sigma_components, \"o\", color = robust_color, markersize = markersize)\n",
    "axes[0].plot(X_test, strict_sigma, \"o\", color = strict_color, markersize = markersize)\n",
    "axes[0].set_title(\"Unstandardized Estimation of Sigma\")\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"Var[Y]\")\n",
    "\n",
    "axes[1].plot(X_test, S1_test - S1_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[1].plot(X_test, sigma - sigma.mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[1].plot(X_test, rob_sigma - rob_sigma.mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "axes[1].plot(X_test, strict_sigma - strict_sigma.mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[1].set_title(\"Standardized Estimation of Sigma\")\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"Var[Y]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onedimensional Scenario with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "########## Drawing Covariate Samples ##########\n",
    "n_train, n_val, n_test = 10000, 10000, 10000\n",
    "prop_corrupt = 0.2\n",
    "Uniform = dist.Uniform(0, 1)\n",
    "\n",
    "X_train = Uniform.sample(sample_shape = [n_train, 1])\n",
    "X_val = Uniform.sample(sample_shape = [n_val, 1])\n",
    "X_test = Uniform.sample(sample_shape = [n_test, 1])\n",
    "\n",
    "########## Training Dataset ##########\n",
    "F1_train = F1(X_train)\n",
    "S1_train = S1(X_train)\n",
    "\n",
    "y_train = F1_train + torch.normal(mean=torch.zeros(n_train), std = S1_train)\n",
    "y_train = y_train.view(n_train, 1)\n",
    "\n",
    "corrupted_train_indices = torch.tensor(random.sample(range(1, n_train), int(n_train * prop_corrupt)))\n",
    "y_train[corrupted_train_indices] = torch.normal(3 - X_train[corrupted_train_indices] + torch.sin(X_train[corrupted_train_indices] * 2.5 * torch.pi), 2)\n",
    "\n",
    "intact_train_indices = torch.ones(n_train, dtype=bool)\n",
    "intact_train_indices[corrupted_train_indices] = False\n",
    "\n",
    "########## Validation Dataset ###########\n",
    "F1_val = F1(X_val)\n",
    "S1_val = S1(X_val)\n",
    "\n",
    "y_val = F1_val + torch.normal(torch.zeros(n_val), std = S1_val)\n",
    "y_val = y_val.view(n_val, 1)\n",
    "\n",
    "corrupted_val_indices = torch.tensor(random.sample(range(1, n_val), int(n_val * prop_corrupt)))\n",
    "y_val[corrupted_val_indices] = torch.normal(3 - X_val[corrupted_val_indices] + torch.sin(X_train[corrupted_val_indices] * 2.5 * torch.pi), 2)\n",
    "\n",
    "########## Testing Dataset ##########\n",
    "F1_test = F1(X_test)\n",
    "S1_test = S1(X_test)\n",
    "\n",
    "y_test = F1_test + torch.normal(torch.zeros(n_test), std = S1_test)\n",
    "y_test = y_test.view(n_test, 1)\n",
    "\n",
    "corrupted_test_indices = torch.tensor(random.sample(range(1, n_test), int(n_test * prop_corrupt)))\n",
    "y_test[corrupted_test_indices] = torch.normal(3 - X_test[corrupted_test_indices] + torch.sin(X_train[corrupted_test_indices] * 2.5 * torch.pi), 2)\n",
    "\n",
    "intact_test_indices = torch.ones(n_test, dtype=bool)\n",
    "intact_test_indices[corrupted_test_indices] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=[16, 5])\n",
    "\n",
    "# Colors\n",
    "intact_color = \"cornflowerblue\"\n",
    "corrupted_color = \"turquoise\"\n",
    "\n",
    "# Scatterplot (Left subplot)\n",
    "axes[0].plot(X_train[intact_train_indices], y_train[intact_train_indices], \"o\", color = intact_color, markersize = 2, alpha = 0.7, label = \"Data of Interest\")\n",
    "axes[0].plot(X_train[corrupted_train_indices], y_train[corrupted_train_indices], \"o\", color = corrupted_color, markersize = 2, alpha = 0.7, label = \"Outliers\")\n",
    "axes[0].set_title(\"Scatterplot of X and Y\")\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"Y\")\n",
    "\n",
    "# Histogram (Right subplot)\n",
    "axes[1].hist(y_train[intact_train_indices].detach().numpy(), bins = 30, color = intact_color, alpha = 0.7, label = \"Data of Interest\")\n",
    "axes[1].hist(y_train[corrupted_train_indices].detach().numpy(), bins = 30, color = corrupted_color, alpha = 0.7, label = \"Outliers\")\n",
    "axes[1].set_title(\"Histogram of Y\")\n",
    "axes[1].set_xlabel(\"Y\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Legends\n",
    "axes[0].legend(loc=\"upper right\")\n",
    "axes[1].legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = [16, 5])\n",
    "\n",
    "linewidth = 2\n",
    "true_color = \"cyan\"\n",
    "linestyle = (0, (3, 2))\n",
    "\n",
    "axes[0].plot(X_test, F1(X_test), \"o\", markersize = 1.5)\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"Mean\")\n",
    "axes[0].set_title(\"Effect of X on Mean of Y\")\n",
    "\n",
    "axes[1].plot(X_test, S1(X_test), \"o\", markersize = 1.5)\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"SD\")\n",
    "axes[1].set_title(\"Effect of X on SD of Y\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler1, scaler2, scaler3 = StandardScaler(), StandardScaler(), StandardScaler()\n",
    "\n",
    "X_train_scaled = torch.tensor(scaler.fit_transform(X_train), dtype = torch.float32)\n",
    "X_val_scaled = torch.tensor(scaler.fit_transform(X_val), dtype = torch.float32)\n",
    "X_test_scaled = torch.tensor(scaler.fit_transform(X_test), dtype = torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(scaler1.fit_transform(y_train), dtype = torch.float32)\n",
    "y_val_scaled = torch.tensor(scaler2.fit_transform(y_val), dtype = torch.float32)\n",
    "y_test_scaled = torch.tensor(scaler3.fit_transform(y_test), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = NormalNAMLSS(1)\n",
    "nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_nam = NormalNAMLSS(1)\n",
    "robust_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_nam = NormalNAMLSS(1)\n",
    "strict_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Predicting Parameters on scaled data ##########\n",
    "mu, sigma = nam.predict(X_test_scaled)\n",
    "robust_mu, robust_sigma = robust_nam.predict(X_test_scaled)\n",
    "strict_mu, strict_sigma = strict_nam.predict(X_test_scaled)\n",
    "\n",
    "mu_components, sigma_components = nam.marginal_effects(X_test_scaled)\n",
    "robust_mu_components, robust_sigma_components = robust_nam.marginal_effects(X_test_scaled)\n",
    "strict_mu_components, strict_sigma_components = strict_nam.marginal_effects(X_test_scaled)\n",
    "\n",
    "########## Rescaling predicted parameters ##########\n",
    "mu = mu * scaler3.scale_ + scaler3.mean_\n",
    "robust_mu = robust_mu * scaler3.scale_ + scaler3.mean_\n",
    "strict_mu = strict_mu * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "sigma = sigma * scaler3.scale_\n",
    "robust_sigma = robust_sigma * scaler3.scale_\n",
    "strict_sigma = strict_sigma * scaler3.scale_\n",
    "\n",
    "mu_components = mu_components * scaler3.scale_ + scaler3.mean_\n",
    "robust_mu_components = robust_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "strict_mu_components = strict_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "sigma_components = sigma_components * scaler3.scale_\n",
    "robust_sigma_components = robust_sigma_components * scaler3.scale_\n",
    "strict_sigma_components = strict_sigma_components * scaler3.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test = X_test.squeeze()\n",
    "\n",
    "sorted_incides = np.argsort(X_test)\n",
    "X_test_sorted = X_test[sorted_incides]\n",
    "\n",
    "mu_sorted = mu[sorted_incides]\n",
    "robust_mu_sorted = robust_mu[sorted_incides]\n",
    "strict_mu_sorted = strict_mu[sorted_incides]\n",
    "\n",
    "sigma_sorted = sigma[sorted_incides]\n",
    "robust_sigma_sorted = robust_sigma[sorted_incides]\n",
    "strict_sigma_sorted = strict_sigma[sorted_incides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Predicted Quantiles ##########\n",
    "lower = mu_sorted - 1.96 * sigma_sorted\n",
    "upper = mu_sorted + 1.96 * sigma_sorted\n",
    "\n",
    "robust_lower = robust_mu_sorted - 1.96 * robust_sigma_sorted\n",
    "robust_upper = robust_mu_sorted + 1.96 * robust_sigma_sorted\n",
    "\n",
    "strict_lower = strict_mu_sorted - 1.96 * strict_sigma_sorted\n",
    "strict_upper = strict_mu_sorted + 1.96 * strict_sigma_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize = 3\n",
    "alpha = 0.4\n",
    "\n",
    "true_color = \"cornflowerblue\"\n",
    "outlier_color = \"turquoise\"\n",
    "unregulated_color = \"#2ca02c\"\n",
    "robust_color = \"indigo\"\n",
    "strict_color = \"red\"\n",
    "\n",
    "linewidth = 3\n",
    "linestyle = (0, (5, 2))\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = [16, 5])\n",
    "\n",
    "axes[0].plot(X_test[intact_test_indices], y_test[intact_test_indices], \"o\", color = true_color, markersize = 2, alpha = 0.7)\n",
    "axes[0].plot(X_test[corrupted_test_indices], y_test[corrupted_test_indices], \"o\", color = outlier_color, markersize = 2, alpha = 0.5)\n",
    "axes[0].plot(X_test_sorted, lower, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, upper, color = unregulated_color, linewidth = linewidth, linestyle= linestyle)\n",
    "axes[0].set_title(\"95% Intervals (True Values + Outliers)\")\n",
    "axes[0].set_ylim([-4,10])\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"Y\")\n",
    "\n",
    "axes[1].plot(X_test[intact_test_indices], y_test[intact_test_indices], \"o\", color = true_color, markersize = 2, alpha = 0.7)\n",
    "axes[1].plot(X_test_sorted, lower, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, upper, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].set_title(\"95% Intervals (True Values Only)\")\n",
    "axes[1].set_ylim([-4,10])\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"Y\")\n",
    "\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=unregulated_color, linewidth=markersize, label=\"No Penalty\")\n",
    "]\n",
    "\n",
    "\n",
    "axes[0].legend(handles = legend_handles, loc = \"upper left\")\n",
    "axes[1].legend(handles = legend_handles, loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize = 3\n",
    "alpha = 0.4\n",
    "\n",
    "linewidth = 3\n",
    "linestyle = (0, (5, 2))\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = [16, 5])\n",
    "\n",
    "axes[0].plot(X_test[intact_test_indices], y_test[intact_test_indices], \"o\", color = true_color, markersize = 2, alpha = 0.7)\n",
    "axes[0].plot(X_test[corrupted_test_indices], y_test[corrupted_test_indices], \"o\", color = outlier_color, markersize = 2, alpha = 0.5)\n",
    "axes[0].plot(X_test_sorted, lower, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, upper, color = unregulated_color, linewidth = linewidth, linestyle= linestyle)\n",
    "axes[0].plot(X_test_sorted, robust_lower, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, robust_upper, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].set_title(\"95% Intervals (True Values + Outliers)\")\n",
    "axes[0].set_ylim([-4,10])\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"Y\")\n",
    "\n",
    "axes[1].plot(X_test[intact_test_indices], y_test[intact_test_indices], \"o\", color = true_color, markersize = 2, alpha = 0.7)\n",
    "axes[1].plot(X_test_sorted, lower, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, upper, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, robust_lower, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, robust_upper, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].set_title(\"95% Intervals (True Values Only)\")\n",
    "axes[1].set_ylim([-4,10])\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"Y\")\n",
    "\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=unregulated_color, linewidth=markersize, label=\"No Penalty\"),\n",
    "    plt.Line2D([0], [0], color=robust_color, linewidth=markersize, label=\"c = 3\"),\n",
    "]\n",
    "\n",
    "\n",
    "axes[0].legend(handles = legend_handles, loc = \"upper left\")\n",
    "axes[1].legend(handles = legend_handles, loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize = 3\n",
    "alpha = 0.4\n",
    "\n",
    "linewidth = 3\n",
    "linestyle = (0, (5, 2))\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = [16, 5])\n",
    "\n",
    "axes[0].plot(X_test[intact_test_indices], y_test[intact_test_indices], \"o\", color = true_color, markersize = 2, alpha = 0.7)\n",
    "axes[0].plot(X_test[corrupted_test_indices], y_test[corrupted_test_indices], \"o\", color = outlier_color, markersize = 2, alpha = 0.5)\n",
    "axes[0].plot(X_test_sorted, lower, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, upper, color = unregulated_color, linewidth = linewidth, linestyle= linestyle)\n",
    "axes[0].plot(X_test_sorted, robust_lower, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, robust_upper, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, strict_lower, color = strict_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, strict_upper, color = strict_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].set_title(\"95% Intervals (True Values + Outliers)\")\n",
    "axes[0].set_ylim([-4,10])\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"Y\")\n",
    "\n",
    "axes[1].plot(X_test[intact_test_indices], y_test[intact_test_indices], \"o\", color = true_color, markersize = 2, alpha = 0.7)\n",
    "axes[1].plot(X_test_sorted, lower, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, upper, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, robust_lower, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, robust_upper, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, strict_lower, color = strict_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, strict_upper, color = strict_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].set_title(\"95% Intervals (True Values Only)\")\n",
    "axes[1].set_ylim([-4,10])\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"Y\")\n",
    "\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=unregulated_color, linewidth=markersize, label=\"No Penalty\"),\n",
    "    plt.Line2D([0], [0], color=robust_color, linewidth=markersize, label=\"c = 3\"),\n",
    "    plt.Line2D([0], [0], color=strict_color, linewidth=markersize, label=\"c = 1\"),\n",
    "]\n",
    "\n",
    "\n",
    "axes[0].legend(handles = legend_handles, loc = \"upper left\")\n",
    "axes[1].legend(handles = legend_handles, loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = [16, 5])\n",
    "\n",
    "linewidth = 2\n",
    "true_color = \"cyan\"\n",
    "linestyle = (0, (3, 2))\n",
    "\n",
    "axes[0].plot(X_test_sorted, F1_test[sorted_incides], color = true_color, linewidth = linewidth + 1)\n",
    "axes[0].plot(X_test_sorted, mu_sorted, color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, robust_mu_sorted, color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].plot(X_test_sorted, strict_mu_sorted, color = strict_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[0].set_title(\"Estimation of Mu\")\n",
    "\n",
    "axes[1].plot(X_test_sorted, S1_test[sorted_incides], color = true_color, linewidth = linewidth + 1)\n",
    "axes[1].plot(X_test_sorted, sigma[sorted_incides], color = unregulated_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, robust_sigma[sorted_incides], color = robust_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].plot(X_test_sorted, strict_sigma[sorted_incides], color = strict_color, linewidth = linewidth, linestyle = linestyle)\n",
    "axes[1].set_title(\"Estimation of Sigma\")\n",
    "axes[1].set_ylim([0.4, 2.1])\n",
    "\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color = true_color, linewidth = linewidth, label = \"True Effect\"),\n",
    "    plt.Line2D([0], [0], color = unregulated_color, linewidth=linewidth, label = \"No Penalty\"),\n",
    "    plt.Line2D([0], [0], color = robust_color, linewidth=linewidth, label = \"c = 3\"),\n",
    "    plt.Line2D([0], [0], color = strict_color, linewidth=linewidth, label = \"c = 1\"),\n",
    "]\n",
    "\n",
    "axes[0].legend(handles = legend_handles, loc = \"upper left\")\n",
    "axes[1].legend(handles = legend_handles, loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Compute Mean Squared Errors\n",
    "mse_mu_no_penalty = np.mean((mu_sorted.squeeze() - F1_test[sorted_incides]).numpy()**2) * 100\n",
    "mse_mu_robust = np.mean((robust_mu_sorted.squeeze() - F1_test[sorted_incides]).numpy()**2) * 100\n",
    "mse_mu_strict = np.mean((strict_mu_sorted.squeeze() - F1_test[sorted_incides]).numpy()**2) * 100\n",
    "\n",
    "mse_sigma_no_penalty = np.mean((sigma[sorted_incides].squeeze() - S1_test[sorted_incides]).numpy()**2) * 100\n",
    "mse_sigma_robust = np.mean((robust_sigma[sorted_incides].squeeze() - S1_test[sorted_incides]).numpy()**2) * 100\n",
    "mse_sigma_strict = np.mean((strict_sigma[sorted_incides].squeeze() - S1_test[sorted_incides]).numpy()**2) * 100\n",
    "\n",
    "# Create a DataFrame\n",
    "mse_table = pd.DataFrame({\n",
    "    \"Method\": [\"No Penalty\", \"c = 3\", \"c = 1\"],\n",
    "    \"MSE (Mu)\": [mse_mu_no_penalty, mse_mu_robust, mse_mu_strict],\n",
    "    \"MSE (Sigma)\": [mse_sigma_no_penalty, mse_sigma_robust, mse_sigma_strict]\n",
    "})\n",
    "\n",
    "mse_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_test[sorted_incides].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional Scenario - No Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(X):\n",
    "    return (2 * X + torch.sin(X * 2.5 * torch.pi)).squeeze()\n",
    "\n",
    "def F2(X):\n",
    "    return (3 - 3 * X ** 2).squeeze()\n",
    "\n",
    "def F3(X):\n",
    "    return (12 * (X - 0.5) ** 2).squeeze()\n",
    "\n",
    "def S1(X):\n",
    "    return torch.exp(-0.5 + 2 * X - 1.5 * X ** 2).squeeze()\n",
    "\n",
    "def S2(X):\n",
    "    return (1.2 - 1/2 * X).squeeze()\n",
    "\n",
    "def S3(X):\n",
    "    return (X/X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "\n",
    "########## Drawing Covariate Samples ##########\n",
    "n_train, n_val, n_test = 10000, 10000, 10000\n",
    "n_var = 3\n",
    "Uniform = dist.Uniform(0, 1)\n",
    "\n",
    "X_train = Uniform.sample(sample_shape = [n_train, n_var])\n",
    "X_val = Uniform.sample(sample_shape = [n_val, n_var])\n",
    "X_test = Uniform.sample(sample_shape = [n_test, n_var])\n",
    "\n",
    "########## Training Dataset ##########\n",
    "F1_train = F1(X_train[:,0])\n",
    "F2_train = F2(X_train[:,1])\n",
    "F3_train = F3(X_train[:,2])\n",
    "\n",
    "S1_train = S1(X_train[:,0])\n",
    "S2_train = S2(X_train[:,1])\n",
    "S3_train = S3(X_train[:,2])\n",
    "\n",
    "y_train = torch.normal(mean = F1_train + F2_train + F3_train, std = S1_train + S2_train + S3_train)\n",
    "y_train = y_train.view(n_train, 1)\n",
    "\n",
    "########## Validation Dataset ###########\n",
    "F1_val = F1(X_val[:,0])\n",
    "F2_val = F2(X_val[:,1])\n",
    "F3_val = F3(X_val[:,2])\n",
    "\n",
    "S1_val = S1(X_val[:,0])\n",
    "S2_val = S2(X_val[:,1])\n",
    "S3_val = S3(X_val[:,2])\n",
    "\n",
    "y_val =  + torch.normal(mean = F1_val + F2_val + F3_val, std = S1_val + S2_val + S3_val)\n",
    "y_val = y_val.view(n_val, 1)\n",
    "\n",
    "########## Testing Dataset ##########\n",
    "F1_test = F1(X_test[:,0])\n",
    "F2_test = F2(X_test[:,1])\n",
    "F3_test = F3(X_test[:,2])\n",
    "\n",
    "S1_test = S1(X_test[:,0])\n",
    "S2_test = S2(X_test[:,1])\n",
    "S3_test = S3(X_test[:,2])\n",
    "\n",
    "y_test = torch.normal(mean = F1_test + F2_test + F3_test, std = S1_test + S2_test + S3_test)\n",
    "y_test = y_test.view(n_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler1, scaler2, scaler3 = StandardScaler(), StandardScaler(), StandardScaler()\n",
    "\n",
    "X_train_scaled = torch.tensor(scaler.fit_transform(X_train), dtype = torch.float32)\n",
    "X_val_scaled = torch.tensor(scaler.fit_transform(X_val), dtype = torch.float32)\n",
    "X_test_scaled = torch.tensor(scaler.fit_transform(X_test), dtype = torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(scaler1.fit_transform(y_train), dtype = torch.float32)\n",
    "y_val_scaled = torch.tensor(scaler2.fit_transform(y_val), dtype = torch.float32)\n",
    "y_test_scaled = torch.tensor(scaler3.fit_transform(y_test), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = NormalNAMLSS(3)\n",
    "nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_nam = NormalNAMLSS(3)\n",
    "robust_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_nam = NormalNAMLSS(3)\n",
    "strict_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Predicting Parameters on scaled data ##########\n",
    "mu, sigma = nam.predict(X_test_scaled)\n",
    "rob_mu, rob_sigma = robust_nam.predict(X_test_scaled)\n",
    "strict_mu, strict_sigma = strict_nam.predict(X_test_scaled)\n",
    "\n",
    "mu_components, sigma_components = nam.marginal_effects(X_test_scaled)\n",
    "robust_mu_components, robust_sigma_components = robust_nam.marginal_effects(X_test_scaled)\n",
    "strict_mu_components, strict_sigma_components = strict_nam.marginal_effects(X_test_scaled)\n",
    "\n",
    "########## Rescaling predicted parameters ##########\n",
    "mu = mu * scaler3.scale_ + scaler3.mean_\n",
    "rob_mu = rob_mu * scaler3.scale_ + scaler3.mean_\n",
    "strict_mu = strict_mu * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "sigma = sigma * scaler3.scale_\n",
    "rob_sigma = rob_sigma * scaler3.scale_\n",
    "strict_sigma = strict_sigma * scaler3.scale_\n",
    "\n",
    "mu_components = mu_components * scaler3.scale_ + scaler3.mean_\n",
    "robust_mu_components = robust_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "strict_mu_components = strict_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "sigma_components = sigma_components * scaler3.scale_\n",
    "robust_sigma_components = robust_sigma_components * scaler3.scale_\n",
    "strict_sigma_components = strict_sigma_components * scaler3.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Predicted Quantiles ##########\n",
    "lower = mu - 1.96 * sigma\n",
    "upper = mu + 1.96 * sigma\n",
    "\n",
    "robust_lower = rob_mu - 1.96 * rob_sigma\n",
    "robust_upper = rob_mu + 1.96 * rob_sigma\n",
    "\n",
    "strict_lower = strict_mu - 1.96 * strict_sigma\n",
    "strict_upper = strict_mu + 1.96 * strict_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize = 3\n",
    "alpha = 0.4\n",
    "\n",
    "true_color = \"C0\"\n",
    "unregulated_color = \"C2\"\n",
    "robust_color = \"orange\"\n",
    "strict_color = \"tomato\"\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [20, 5])\n",
    "\n",
    "axes[0].plot(X_test[:,0], F1_test - F1_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[0].plot(X_test[:,0], mu_components[:,0] - mu_components[:,0].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "# axes[0].plot(X_test[:,0], robust_mu_components[:,0] - robust_mu_components[:,0].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "# axes[0].plot(X_test[:,0], strict_mu_components[:,0] - strict_mu_components[:,0].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[0].set_title(\"Estimated Mean Curves\")\n",
    "\n",
    "axes[1].plot(X_test[:,1], F2_test - F2_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[1].plot(X_test[:,1], mu_components[:,1] - mu_components[:,1].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "# axes[1].plot(X_test[:,1], robust_mu_components[:,1] - robust_mu_components[:,1].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "# axes[1].plot(X_test[:,1], strict_mu_components[:,1] - strict_mu_components[:,1].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[1].set_title(\"Estimated Mean Curves\")\n",
    "\n",
    "axes[2].plot(X_test[:,2], F3_test - F3_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[2].plot(X_test[:,2], mu_components[:,2] - mu_components[:,2].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "# axes[2].plot(X_test[:,2], robust_mu_components[:,2] - robust_mu_components[:,2].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "# axes[2].plot(X_test[:,2], strict_mu_components[:,2] - strict_mu_components[:,2].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[2].set_title(\"Estimated Mean Curves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [16, 5])\n",
    "\n",
    "axes[0].plot(X_test[:,0], S1_test - S1_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[0].plot(X_test[:,0], sigma_components[:,0] - sigma_components[:,0].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "# axes[0].plot(X_test[:,0], robust_sigma_components[:,0] - robust_sigma_components[:,0].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "# axes[0].plot(X_test[:,0], strict_sigma_components[:,0] -strict_sigma_components[:,0].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[0].set_title(\"Estimated Sigma Curves\")\n",
    "\n",
    "axes[1].plot(X_test[:,1], S2_test - S2_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[1].plot(X_test[:,1], sigma_components[:,1] - sigma_components[:,1].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "# axes[1].plot(X_test[:,1], robust_sigma_components[:,1] - robust_sigma_components[:,1].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "# axes[1].plot(X_test[:,1], strict_sigma_components[:,1] -strict_sigma_components[:,1].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[1].set_title(\"Estimated Sigma Curves\")\n",
    "\n",
    "axes[2].plot(X_test[:,2], S3_test - S3_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[2].plot(X_test[:,2], sigma_components[:,2] - sigma_components[:,2].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "# axes[2].plot(X_test[:,2], robust_sigma_components[:,2] - robust_sigma_components[:,2].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "# axes[2].plot(X_test[:,2], strict_sigma_components[:,2] -strict_sigma_components[:,2].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[2].set_ylim([-0.3,0.3])\n",
    "axes[2].set_title(\"Estimated Sigma Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional Scenario with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "import random\n",
    "\n",
    "########## Drawing Covariate Samples ##########\n",
    "n_train, n_val, n_test = 10000, 10000, 10000\n",
    "prop_corrupt = 0.1\n",
    "n_var = 3\n",
    "Uniform = dist.Uniform(0, 1)\n",
    "\n",
    "X_train = Uniform.sample(sample_shape = [n_train, n_var])\n",
    "X_val = Uniform.sample(sample_shape = [n_val, n_var])\n",
    "X_test = Uniform.sample(sample_shape = [n_test, n_var])\n",
    "\n",
    "########## Training Dataset ##########\n",
    "F1_train = F1(X_train[:,0])\n",
    "F2_train = F2(X_train[:,1])\n",
    "F3_train = F3(X_train[:,2])\n",
    "\n",
    "S1_train = S1(X_train[:,0])\n",
    "S2_train = S2(X_train[:,1])\n",
    "S3_train = S3(X_train[:,2])\n",
    "\n",
    "y_train = torch.normal(mean = F1_train + F2_train + F3_train, std = S1_train + S2_train + S3_train)\n",
    "corrupted_train_indices = torch.tensor(random.sample(range(1, n_train), int(n_train * prop_corrupt)))\n",
    "y_train[corrupted_train_indices] = torch.normal(torch.ones(len(corrupted_train_indices)) * 15, torch.ones(len(corrupted_train_indices)) * 2) # TODO: Bessere Outlier\n",
    "y_train = y_train.view(n_train, 1)\n",
    "\n",
    "intact_train_indices = torch.ones(n_train, dtype=bool)\n",
    "intact_train_indices[corrupted_train_indices] = False\n",
    "\n",
    "########## Validation Dataset ###########\n",
    "F1_val = F1(X_val[:,0])\n",
    "F2_val = F2(X_val[:,1])\n",
    "F3_val = F3(X_val[:,2])\n",
    "\n",
    "S1_val = S1(X_val[:,0])\n",
    "S2_val = S2(X_val[:,1])\n",
    "S3_val = S3(X_val[:,2])\n",
    "\n",
    "y_val =  + torch.normal(mean = F1_val + F2_val + F3_val, std = S1_val + S2_val + S3_val)\n",
    "corrupted_val_indices = torch.tensor(random.sample(range(1, n_val), int(n_val * prop_corrupt)))\n",
    "y_val[corrupted_val_indices] = torch.normal(torch.ones(len(corrupted_val_indices)) * 15, torch.ones(len(corrupted_val_indices)) * 2) # TODO: Bessere Outlier\n",
    "y_val = y_val.view(n_val, 1)\n",
    "\n",
    "########## Testing Dataset ##########\n",
    "F1_test = F1(X_test[:,0])\n",
    "F2_test = F2(X_test[:,1])\n",
    "F3_test = F3(X_test[:,2])\n",
    "\n",
    "S1_test = S1(X_test[:,0])\n",
    "S2_test = S2(X_test[:,1])\n",
    "S3_test = S3(X_test[:,2])\n",
    "\n",
    "y_test = torch.normal(mean = F1_test + F2_test + F3_test, std = S1_test + S2_test + S3_test)\n",
    "corrupted_test_indices = torch.tensor(random.sample(range(1, n_test), int(n_test * prop_corrupt)))\n",
    "y_test[corrupted_test_indices] = torch.normal(torch.ones(len(corrupted_test_indices)) * 15, torch.ones(len(corrupted_test_indices)) * 2) # TODO: Bessere Outlier\n",
    "\n",
    "y_test = y_test.view(n_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_train[intact_train_indices].numpy(), bins = 30, color = \"royalblue\", alpha = 0.7)\n",
    "plt.hist(y_train[corrupted_train_indices].numpy(), bins = 30, color = \"tomato\", alpha = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler1, scaler2, scaler3 = StandardScaler(), StandardScaler(), StandardScaler()\n",
    "\n",
    "X_train_scaled = torch.tensor(scaler.fit_transform(X_train), dtype = torch.float32)\n",
    "X_val_scaled = torch.tensor(scaler.fit_transform(X_val), dtype = torch.float32)\n",
    "X_test_scaled = torch.tensor(scaler.fit_transform(X_test), dtype = torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(scaler1.fit_transform(y_train), dtype = torch.float32)\n",
    "y_val_scaled = torch.tensor(scaler2.fit_transform(y_val), dtype = torch.float32)\n",
    "y_test_scaled = torch.tensor(scaler3.fit_transform(y_test), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = NormalNAMLSS(3)\n",
    "nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_nam = NormalNAMLSS(3)\n",
    "robust_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_nam = NormalNAMLSS(3)\n",
    "strict_nam.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor=torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Predicting Parameters on scaled data ##########\n",
    "mu, sigma = nam.predict(X_test_scaled)\n",
    "rob_mu, rob_sigma = robust_nam.predict(X_test_scaled)\n",
    "strict_mu, strict_sigma = strict_nam.predict(X_test_scaled)\n",
    "\n",
    "mu_components, sigma_components = nam.marginal_effects(X_test_scaled)\n",
    "robust_mu_components, robust_sigma_components = robust_nam.marginal_effects(X_test_scaled)\n",
    "strict_mu_components, strict_sigma_components = strict_nam.marginal_effects(X_test_scaled)\n",
    "\n",
    "########## Rescaling predicted parameters ##########\n",
    "mu = mu * scaler3.scale_ + scaler3.mean_\n",
    "rob_mu = rob_mu * scaler3.scale_ + scaler3.mean_\n",
    "strict_mu = strict_mu * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "sigma = sigma * scaler3.scale_\n",
    "rob_sigma = rob_sigma * scaler3.scale_\n",
    "strict_sigma = strict_sigma * scaler3.scale_\n",
    "\n",
    "mu_components = mu_components * scaler3.scale_ + scaler3.mean_\n",
    "robust_mu_components = robust_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "strict_mu_components = strict_mu_components * scaler3.scale_ + scaler3.mean_\n",
    "\n",
    "sigma_components = sigma_components * scaler3.scale_\n",
    "robust_sigma_components = robust_sigma_components * scaler3.scale_\n",
    "strict_sigma_components = strict_sigma_components * scaler3.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Predicted Quantiles ##########\n",
    "lower = mu - 1.96 * sigma\n",
    "upper = mu + 1.96 * sigma\n",
    "\n",
    "robust_lower = rob_mu - 1.96 * rob_sigma\n",
    "robust_upper = rob_mu + 1.96 * rob_sigma\n",
    "\n",
    "strict_lower = strict_mu - 1.96 * strict_sigma\n",
    "strict_upper = strict_mu + 1.96 * strict_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize = 2\n",
    "alpha = 0.4\n",
    "\n",
    "true_color = \"C0\"\n",
    "unregulated_color = \"C2\"\n",
    "robust_color = \"orange\"\n",
    "strict_color = \"tomato\"\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [16, 5])\n",
    "\n",
    "axes[0].plot(X_test[:,0], F1_test - F1_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[0].plot(X_test[:,0], mu_components[:,0] - mu_components[:,0].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[0].plot(X_test[:,0], robust_mu_components[:,0] - robust_mu_components[:,0].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "axes[0].plot(X_test[:,0], strict_mu_components[:,0] - strict_mu_components[:,0].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[0].set_title(\"Estimated Mean Curves\")\n",
    "\n",
    "axes[1].plot(X_test[:,1], F2_test - F2_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[1].plot(X_test[:,1], mu_components[:,1] - mu_components[:,1].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[1].plot(X_test[:,1], robust_mu_components[:,1] - robust_mu_components[:,1].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "axes[1].plot(X_test[:,1], strict_mu_components[:,1] - strict_mu_components[:,1].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[1].set_title(\"Estimated Mean Curves\")\n",
    "\n",
    "axes[2].plot(X_test[:,2], F3_test - F3_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[2].plot(X_test[:,2], mu_components[:,2] - mu_components[:,2].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[2].plot(X_test[:,2], robust_mu_components[:,2] - robust_mu_components[:,2].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "axes[2].plot(X_test[:,2], strict_mu_components[:,2] - strict_mu_components[:,2].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[2].set_title(\"Estimated Mean Curves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = [16, 5])\n",
    "\n",
    "axes[0].plot(X_test[:,0], S1_test - S1_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[0].plot(X_test[:,0], sigma_components[:,0] - sigma_components[:,0].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[0].plot(X_test[:,0], robust_sigma_components[:,0] - robust_sigma_components[:,0].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "axes[0].plot(X_test[:,0], strict_sigma_components[:,0] -strict_sigma_components[:,0].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[0].set_title(\"Estimated Sigma Curves\")\n",
    "\n",
    "axes[1].plot(X_test[:,1], S2_test - S2_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[1].plot(X_test[:,1], sigma_components[:,1] - sigma_components[:,1].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[1].plot(X_test[:,1], robust_sigma_components[:,1] - robust_sigma_components[:,1].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "axes[1].plot(X_test[:,1], strict_sigma_components[:,1] -strict_sigma_components[:,1].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[1].set_title(\"Estimated Sigma Curves\")\n",
    "\n",
    "axes[2].plot(X_test[:,2], S3_test - S3_test.mean(), \"o\", color = true_color, markersize = markersize)\n",
    "axes[2].plot(X_test[:,2], sigma_components[:,2] - sigma_components[:,2].mean(), \"o\", color = unregulated_color, markersize = markersize)\n",
    "axes[2].plot(X_test[:,2], robust_sigma_components[:,2] - robust_sigma_components[:,2].mean(), \"o\", color = robust_color, markersize = markersize)\n",
    "axes[2].plot(X_test[:,2], strict_sigma_components[:,2] -strict_sigma_components[:,2].mean(), \"o\", color = strict_color, markersize = markersize)\n",
    "axes[2].set_ylim([-1, 1])\n",
    "axes[2].set_title(\"Estimated Sigma Curves\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
