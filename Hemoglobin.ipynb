{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "\n",
    "class NormalNAMLSS(nn.Module):\n",
    "    def __init__(self, n_covariates, hidden_size=16, intercept=False):\n",
    "        super(NormalNAMLSS, self).__init__()\n",
    "\n",
    "        self.submodules = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1, hidden_size),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_size, 2)\n",
    "            ) for _ in range(n_covariates)\n",
    "        ])\n",
    "\n",
    "        self.use_intercept = intercept\n",
    "        if self.use_intercept:\n",
    "            self.intercept = nn.Parameter(torch.zeros(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        param_mat_list = [self.submodules[i](x[:, i:i + 1]) for i in range(x.shape[1])]\n",
    "        x = torch.stack(param_mat_list, dim=1)\n",
    "        mu_components = x[:, :, 0]\n",
    "        sigma_components = F.softplus(x[:, :, 1])\n",
    "\n",
    "        mu = torch.sum(mu_components, dim=1).unsqueeze(dim=1)\n",
    "        sigma = torch.sum(sigma_components, dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        if self.use_intercept:\n",
    "            mu = mu + self.intercept[0]\n",
    "            sigma = sigma + F.softplus(self.intercept[1])\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def nll_loss(self, mu, sigma, y_true, robustness_factor=None):\n",
    "        normal_dist = dist.Normal(mu, sigma)\n",
    "        # log_likelihood = normal_dist.log_prob(y_true).sum()\n",
    "        log_likelihood = normal_dist.log_prob(y_true).mean()\n",
    "\n",
    "        if robustness_factor is not None:\n",
    "            # log_likelihood = torch.log((1 + torch.exp(normal_dist.log_prob(y_true) + robustness_factor)) / (1 + torch.exp(robustness_factor))).sum()\n",
    "            log_likelihood = torch.log((1 + torch.exp(normal_dist.log_prob(y_true) + robustness_factor)) / (1 + torch.exp(robustness_factor))).mean()\n",
    "\n",
    "        nll = -log_likelihood\n",
    "        return nll\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, n_epochs=10000, lr=1e-3, weight_decay=0.0, \n",
    "            early_stopping_patience=10, robustness_factor=None):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            self.train()\n",
    "\n",
    "            # Forward pass and loss computation\n",
    "            mu, sigma = self.forward(X_train)\n",
    "            train_loss = self.nll_loss(mu, sigma, y_train, robustness_factor)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            val_loss = None\n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    mu_val, sigma_val = self.forward(X_val)\n",
    "                    val_loss = self.nll_loss(mu_val, sigma_val, y_val, robustness_factor).item()\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                    best_model_state = self.state_dict()\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if (patience_counter >= early_stopping_patience) and (epoch >= 1000):\n",
    "                    print(f\"Early stopping at epoch {epoch}. Best validation loss: {best_val_loss:.4f}\")\n",
    "                    self.load_state_dict(best_model_state)\n",
    "                    break\n",
    "\n",
    "            if epoch % 100 == 0 or val_loss is not None:\n",
    "                # print(f\"Epoch {epoch} - Train Loss: {train_loss.item():.4f} - Val Loss: {val_loss:.4f}\" if val_loss else f\"Epoch {epoch} - Train Loss: {train_loss.item():.4f}\")\n",
    "                pass\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        mu, sigma = self.forward(x)\n",
    "\n",
    "        mu = mu.detach()\n",
    "        sigma = sigma.detach()\n",
    "\n",
    "        return mu, sigma\n",
    "        \n",
    "\n",
    "    def marginal_effects(self, x):\n",
    "        with torch.no_grad():\n",
    "            param_mat_list = [self.submodules[i](x[:, i:i + 1]) for i in range(x.shape[1])]\n",
    "            x = torch.stack(param_mat_list, dim=1)\n",
    "            mu_components = x[:, :, 0].detach().cpu().numpy()\n",
    "            sigma_components = F.softplus(x[:, :, 1]).detach().cpu().numpy()\n",
    "        return mu_components, sigma_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_gradient(z, c):\n",
    "    return np.exp(z + c)/(1 + np.exp(z + c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_aeberhard_penalty(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, target_mdp, rob_vec):\n",
    "\n",
    "    if rob_vec is None:\n",
    "        rob_vec = torch.tensor(list(np.arange(2.5, 0, -0.1)), dtype = torch.float32)\n",
    "\n",
    "    rob_vec = torch.tensor(rob_vec)\n",
    "    n_var = X_train_scaled.shape[1]\n",
    "    \n",
    "    prev_mdp = 0\n",
    "    best_rob = None\n",
    "\n",
    "    for rob in rob_vec:\n",
    "        prev_distance = abs(prev_mdp - target_mdp)\n",
    "        w_b_vector = []\n",
    "\n",
    "        candidate_model = NormalNAMLSS(n_var)\n",
    "        candidate_model.fit(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, robustness_factor = rob)\n",
    "        mu, sigma = candidate_model.predict(X_train_scaled)\n",
    "\n",
    "        normal_dist = dist.Normal(mu, sigma)\n",
    "\n",
    "        for _ in range(10):\n",
    "            y_b = torch.normal(mu, sigma)\n",
    "            ll = normal_dist.log_prob(y_b)\n",
    "            w_1b = rho_gradient(ll, rob)\n",
    "            w_b = torch.sum(w_1b) / len(y_b)\n",
    "            w_b_vector.append(w_b)\n",
    "\n",
    "        current_mdp = 1 - torch.median(torch.tensor(w_b_vector, dtype = torch.float32))\n",
    "        current_distance = abs(current_mdp - target_mdp)\n",
    "\n",
    "        if current_distance > prev_distance:\n",
    "            print(f\"stopping at {best_rob} --> mdp: {prev_mdp * 100}%\")\n",
    "            break\n",
    "\n",
    "        best_rob = rob\n",
    "        prev_mdp = current_mdp\n",
    "\n",
    "        print(f\"current_rob = {rob} --> mdp = {prev_mdp}%\")\n",
    "\n",
    "    return best_rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hemoglobin = pd.read_csv(\"Hb-Anon.txt\", delimiter=\"\\t\")\n",
    "hemoglobin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemoglobin = hemoglobin[hemoglobin[\"AGE\"] > 365]\n",
    "# hemoglobin = hemoglobin[hemoglobin[\"AGE\"] < 6570]\n",
    "len(hemoglobin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = hemoglobin[hemoglobin[\"SEX\"] == \"W\"]\n",
    "len(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = hemoglobin[hemoglobin[\"SEX\"] == \"M\"]\n",
    "len(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(female[\"AGE\"], female[\"VAL\"], \"o\", markersize = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(male[\"AGE\"], male[\"VAL\"], \"o\", markersize = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aeberhardt Penalty - Female Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "female_df = hemoglobin[hemoglobin[\"SEX\"]==\"W\"][[\"AGE\", \"VAL\"]]\n",
    "female_df = female_df.to_numpy()\n",
    "\n",
    "training_sample_indices = random.sample(range(1, len(female_df)), int(50000))\n",
    "x_train = female_df[training_sample_indices, 0]\n",
    "y_train = female_df[training_sample_indices, 1]\n",
    "\n",
    "validation_sample_indices = random.sample(range(1, len(female_df)), int(50000))\n",
    "x_val = female_df[validation_sample_indices, 0]\n",
    "y_val = female_df[validation_sample_indices, 1]\n",
    "\n",
    "testing_sample_indices = random.sample(range(1, len(female_df)), int(50000))\n",
    "x_test = female_df[testing_sample_indices, 0]\n",
    "y_test = female_df[testing_sample_indices, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_test/365, y_test, \"o\", markersize = 0.1, color = \"cornflowerblue\")\n",
    "plt.ylabel(\"Hemoglobin Level (g/dL)\")\n",
    "plt.xlabel(\"Age (Years)\")\n",
    "plt.title(\"Measured Hemoglobin Levels for Female Children\")\n",
    "plt.ylim(5, 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train).unsqueeze(1)\n",
    "x_val = torch.tensor(x_val).unsqueeze(1)\n",
    "x_test = torch.tensor(x_test).unsqueeze(1)\n",
    "\n",
    "y_train = torch.tensor(y_train).unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_scaler, y_scaler = StandardScaler(), StandardScaler()\n",
    "\n",
    "x_train_scaled = torch.tensor(x_scaler.fit_transform(x_train), dtype = torch.float32)\n",
    "x_val_scaled = torch.tensor(x_scaler.transform(x_val), dtype = torch.float32)\n",
    "x_test_scaled = torch.tensor(x_scaler.transform(x_test), dtype = torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(y_scaler.fit_transform(y_train), dtype = torch.float32)\n",
    "y_val_scaled = torch.tensor(y_scaler.transform(y_val), dtype = torch.float32)\n",
    "y_test_scaled = torch.tensor(y_scaler.transform(y_test), dtype = torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust_c = get_aeberhard_penalty(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, 0.5, rob_vec = list(np.arange(1, -2, -0.1)))\n",
    "# strict_c = get_aeberhard_penalty(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, 0.6, rob_vec = list(np.arange(0, -2, -0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5%: rob = 4.4 --> mdp = 5.17\n",
    "- 10%: rob = 3.5 --> mdp = 10.2\n",
    "- 20%: rob = 2.5 --> mdp = 19.5\n",
    "- 30%: rob = 1.6 --> mdp = 30.0\n",
    "- 40%: rob = 0.9 --> mdp = 39.98\n",
    "- 50%: rob = 0.3 --> mdp = 49.98\n",
    "- 60%: rob = -0.4 --> mdp = 60.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_c = 0.3\n",
    "strict_c = -0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = NormalNAMLSS(1)\n",
    "nam.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled)\n",
    "\n",
    "robust_nam = NormalNAMLSS(1)\n",
    "robust_nam.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, robustness_factor = torch.tensor(robust_c))\n",
    "\n",
    "strict_nam = NormalNAMLSS(1)\n",
    "strict_nam .fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, robustness_factor = torch.tensor(strict_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting parameters based on scaled values\n",
    "mu, sigma = nam.predict(x_test_scaled)\n",
    "robust_mu, robust_sigma = robust_nam.predict(x_test_scaled)\n",
    "strict_mu, strict_sigma = strict_nam.predict(x_test_scaled)\n",
    "\n",
    "# Rescaling the predictions for plotting\n",
    "mu = mu * y_scaler.scale_ + y_scaler.mean_\n",
    "robust_mu = robust_mu * y_scaler.scale_ + y_scaler.mean_\n",
    "strict_mu = strict_mu * y_scaler.scale_ + y_scaler.mean_\n",
    "\n",
    "sigma = sigma * y_scaler.scale_\n",
    "robust_sigma = robust_sigma * y_scaler.scale_\n",
    "strict_sigma = strict_sigma * y_scaler.scale_\n",
    "\n",
    "# Calculating 95% reference interval bounds\n",
    "regular_bounds = [mu - 1.96 * sigma, mu + 1.96 * sigma]\n",
    "robust_bounds = [robust_mu - 1.96 * robust_sigma, robust_mu + 1.96 * robust_sigma]\n",
    "strict_bounds = [strict_mu - 1.96 * strict_sigma, strict_mu + 1.96 * strict_sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregulated_color = \"forestgreen\"\n",
    "robust_color = \"indigo\"\n",
    "strict_color = \"crimson\"\n",
    "dot_color = \"cornflowerblue\"\n",
    "\n",
    "linestyle1 = (0, (3, 3))\n",
    "linestyle2 = (0, (5, 3))\n",
    "linewidth = 2\n",
    "\n",
    "# Sorting values for plotting\n",
    "sorted_indices = np.argsort(x_test.squeeze())\n",
    "x_test_sorted = x_test[sorted_indices]/365\n",
    "y_test_sorted = y_test[sorted_indices]\n",
    "\n",
    "plt.plot(x_test_sorted, y_test_sorted, \"o\", markersize = 0.1, color = dot_color)\n",
    "plt.plot(x_test_sorted, regular_bounds[0][sorted_indices], color = unregulated_color, linestyle = linestyle1, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, regular_bounds[1][sorted_indices], color = unregulated_color, linestyle = linestyle1, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, robust_bounds[0][sorted_indices], color = robust_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, robust_bounds[1][sorted_indices], color = robust_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, strict_bounds[0][sorted_indices], color = strict_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, strict_bounds[1][sorted_indices], color = strict_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.ylim((5,20))\n",
    "plt.xlabel(\"Age (Years)\")\n",
    "plt.ylabel(\"Hemoglobin Level (g/dL)\")\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=unregulated_color, label=\"No Penalty\", linestyle = linestyle1),\n",
    "    plt.Line2D([0], [0], color=robust_color, label=\"50% Penalty\"),\n",
    "    plt.Line2D([0], [0], color=strict_color, label=\"60% Penalty\", linestyle = linestyle2)\n",
    "]\n",
    "\n",
    "plt.legend(handles = legend_handles, loc = \"upper left\")\n",
    "plt.title(\"95% Intervals for Healthy Hemoglobin Levels (Female Children)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aeberhardt Penalty - Male Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "male_df = hemoglobin[hemoglobin[\"SEX\"]==\"M\"][[\"AGE\", \"VAL\"]]\n",
    "male_df = male_df.to_numpy()\n",
    "\n",
    "# training_sample_indices = random.sample(range(1, len(male_df)), int(10000))\n",
    "x_train = male_df[training_sample_indices, 0]\n",
    "y_train = male_df[training_sample_indices, 1]\n",
    "\n",
    "# validation_sample_indices = random.sample(range(1, len(male_df)), int(10000))\n",
    "x_val = male_df[validation_sample_indices, 0]\n",
    "y_val = male_df[validation_sample_indices, 1]\n",
    "\n",
    "# testing_sample_indices = random.sample(range(1, len(male_df)), int(10000))\n",
    "x_test = male_df[testing_sample_indices, 0]\n",
    "y_test = male_df[testing_sample_indices, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_test, y_test, \"o\", markersize = 0.1, color = \"cornflowerblue\")\n",
    "plt.xlabel(\"Age (Years)\")\n",
    "plt.ylabel(\"Hemoglobin Level (g/dL)\")\n",
    "plt.title(\"Measured Hemoglobin Levels for Male Children\")\n",
    "plt.ylim(5, 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train).unsqueeze(1)\n",
    "x_val = torch.tensor(x_val).unsqueeze(1)\n",
    "x_test = torch.tensor(x_test).unsqueeze(1)\n",
    "\n",
    "y_train = torch.tensor(y_train).unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_scaler, y_scaler = StandardScaler(), StandardScaler()\n",
    "\n",
    "x_train_scaled = torch.tensor(x_scaler.fit_transform(x_train), dtype = torch.float32)\n",
    "x_val_scaled = torch.tensor(x_scaler.transform(x_val), dtype = torch.float32)\n",
    "x_test_scaled = torch.tensor(x_scaler.transform(x_test), dtype = torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(y_scaler.fit_transform(y_train), dtype = torch.float32)\n",
    "y_val_scaled = torch.tensor(y_scaler.transform(y_val), dtype = torch.float32)\n",
    "y_test_scaled = torch.tensor(y_scaler.transform(y_test), dtype = torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust_c = get_aeberhard_penalty(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, 0.5, rob_vec = list(np.arange(1, -2, -0.1)))\n",
    "# strict_c = get_aeberhard_penalty(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, 0.6, rob_vec = list(np.arange(0, -2, -0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.2 --> 49%\n",
    "- -0.4 --> 59%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_c = 0.2\n",
    "strict_c = -0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = NormalNAMLSS(1)\n",
    "nam.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled)\n",
    "\n",
    "robust_nam = NormalNAMLSS(1)\n",
    "robust_nam.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, robustness_factor = torch.tensor(robust_c))\n",
    "\n",
    "strict_nam = NormalNAMLSS(1)\n",
    "strict_nam .fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, robustness_factor = torch.tensor(strict_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting parameters based on scaled values\n",
    "mu, sigma = nam.predict(x_test_scaled)\n",
    "robust_mu, robust_sigma = robust_nam.predict(x_test_scaled)\n",
    "strict_mu, strict_sigma = strict_nam.predict(x_test_scaled)\n",
    "\n",
    "# Rescaling the predictions for plotting\n",
    "mu = mu * y_scaler.scale_ + y_scaler.mean_\n",
    "robust_mu = robust_mu * y_scaler.scale_ + y_scaler.mean_\n",
    "strict_mu = strict_mu * y_scaler.scale_ + y_scaler.mean_\n",
    "\n",
    "sigma = sigma * y_scaler.scale_\n",
    "robust_sigma = robust_sigma * y_scaler.scale_\n",
    "strict_sigma = strict_sigma * y_scaler.scale_\n",
    "\n",
    "# Calculating 95% reference interval bounds\n",
    "regular_bounds = [mu - 1.96 * sigma, mu + 1.96 * sigma]\n",
    "robust_bounds = [robust_mu - 1.96 * robust_sigma, robust_mu + 1.96 * robust_sigma]\n",
    "strict_bounds = [strict_mu - 1.96 * strict_sigma, strict_mu + 1.96 * strict_sigma]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregulated_color = \"forestgreen\"\n",
    "robust_color = \"indigo\"\n",
    "strict_color = \"crimson\"\n",
    "dot_color = \"cornflowerblue\"\n",
    "\n",
    "linestyle1 = (0, (3, 3))\n",
    "linestyle2 = (0, (5, 3))\n",
    "linewidth = 2\n",
    "\n",
    "# Sorting values for plotting\n",
    "sorted_indices = np.argsort(x_test.squeeze())\n",
    "x_test_sorted = x_test[sorted_indices]/365\n",
    "y_test_sorted = y_test[sorted_indices]\n",
    "\n",
    "plt.plot(x_test_sorted, y_test_sorted, \"o\", markersize = 0.1, color = dot_color)\n",
    "plt.plot(x_test_sorted, regular_bounds[0][sorted_indices], color = unregulated_color, linestyle = linestyle1, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, regular_bounds[1][sorted_indices], color = unregulated_color, linestyle = linestyle1, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, robust_bounds[0][sorted_indices], color = robust_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, robust_bounds[1][sorted_indices], color = robust_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, strict_bounds[0][sorted_indices], color = strict_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, strict_bounds[1][sorted_indices], color = strict_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.ylim((5,20))\n",
    "plt.xlabel(\"Age (Years)\")\n",
    "plt.ylabel(\"Hemoglobin Level (g/dL)\")\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=unregulated_color, label=\"No Penalty\", linestyle = linestyle1),\n",
    "    plt.Line2D([0], [0], color=robust_color, label=\"50% Penalty\", linestyle = linestyle2),\n",
    "    plt.Line2D([0], [0], color=strict_color, label=\"60% Penalty\", linestyle = linestyle2)\n",
    "]\n",
    "\n",
    "plt.legend(handles = legend_handles, loc = \"upper left\")\n",
    "plt.title(\"95% Intervals for Healthy Hemoglobin Levels (Male Children)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffällig: Ausreißer scheinen keine klare Form zu haben, während Gesunde Werte einen ungefähr viesuell feststellbaren Verlauf haben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Penalty - Female Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "female_df = hemoglobin[hemoglobin[\"SEX\"]==\"W\"][[\"AGE\", \"VAL\"]]\n",
    "female_df = female_df.to_numpy()\n",
    "\n",
    "# training_sample_indices = random.sample(range(1, len(female_df)), int(10000))\n",
    "x_train = female_df[training_sample_indices, 0]\n",
    "y_train = female_df[training_sample_indices, 1]\n",
    "\n",
    "# validation_sample_indices = random.sample(range(1, len(female_df)), int(10000))\n",
    "x_val = female_df[validation_sample_indices, 0]\n",
    "y_val = female_df[validation_sample_indices, 1]\n",
    "\n",
    "# testing_sample_indices = random.sample(range(1, len(female_df)), int(10000))\n",
    "x_test = female_df[testing_sample_indices, 0]\n",
    "y_test = female_df[testing_sample_indices, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_test, y_test, \"o\", markersize = 0.1, color = \"cornflowerblue\")\n",
    "plt.ylim(5, 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train).unsqueeze(1)\n",
    "x_val = torch.tensor(x_val).unsqueeze(1)\n",
    "x_test = torch.tensor(x_test).unsqueeze(1)\n",
    "\n",
    "y_train = torch.tensor(y_train).unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_scaler, y_scaler = StandardScaler(), StandardScaler()\n",
    "\n",
    "x_train_scaled = torch.tensor(x_scaler.fit_transform(x_train), dtype = torch.float32)\n",
    "x_val_scaled = torch.tensor(x_scaler.transform(x_val), dtype = torch.float32)\n",
    "x_test_scaled = torch.tensor(x_scaler.transform(x_test), dtype = torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(y_scaler.fit_transform(y_train), dtype = torch.float32)\n",
    "y_val_scaled = torch.tensor(y_scaler.transform(y_val), dtype = torch.float32)\n",
    "y_test_scaled = torch.tensor(y_scaler.transform(y_test), dtype = torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = NormalNAMLSS(1)\n",
    "nam.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled)\n",
    "mu_train, sigma_train = nam.predict(x_train_scaled)\n",
    "normal_dist = dist.Normal(mu_train, sigma_train)\n",
    "log_likelihood = normal_dist.log_prob(y_train_scaled)\n",
    "\n",
    "robust_quantile_value = torch.quantile(log_likelihood, 0.50) # smaller quantile\n",
    "strict_quantile_value = torch.quantile(log_likelihood, 0.60) # larger quantile\n",
    "\n",
    "robust_c = torch.log(torch.exp(-robust_quantile_value) - 1)\n",
    "strict_c = torch.log(torch.exp(-strict_quantile_value) - 1)\n",
    "\n",
    "robust_c = torch.log(torch.exp(-robust_quantile_value) - 1)\n",
    "strict_c = torch.log(torch.exp(-strict_quantile_value) - 1)\n",
    "\n",
    "robust_nam = NormalNAMLSS(1)\n",
    "robust_nam.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, robustness_factor = torch.tensor(robust_c))\n",
    "\n",
    "strict_nam = NormalNAMLSS(1)\n",
    "strict_nam .fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, robustness_factor = torch.tensor(strict_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting parameters based on scaled values\n",
    "mu, sigma = nam.predict(x_test_scaled)\n",
    "robust_mu, robust_sigma = robust_nam.predict(x_test_scaled)\n",
    "strict_mu, strict_sigma = strict_nam.predict(x_test_scaled)\n",
    "\n",
    "# Rescaling the predictions for plotting\n",
    "mu = mu * y_scaler.scale_ + y_scaler.mean_\n",
    "robust_mu = robust_mu * y_scaler.scale_ + y_scaler.mean_\n",
    "strict_mu = strict_mu * y_scaler.scale_ + y_scaler.mean_\n",
    "\n",
    "sigma = sigma * y_scaler.scale_\n",
    "robust_sigma = robust_sigma * y_scaler.scale_\n",
    "strict_sigma = strict_sigma * y_scaler.scale_\n",
    "\n",
    "# Calculating 95% reference interval bounds\n",
    "regular_bounds = [mu - 1.96 * sigma, mu + 1.96 * sigma]\n",
    "robust_bounds = [robust_mu - 1.96 * robust_sigma, robust_mu + 1.96 * robust_sigma]\n",
    "strict_bounds = [strict_mu - 1.96 * strict_sigma, strict_mu + 1.96 * strict_sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregulated_color = \"forestgreen\"\n",
    "robust_color = \"indigo\"\n",
    "strict_color = \"crimson\"\n",
    "dot_color = \"cornflowerblue\"\n",
    "\n",
    "linestyle1 = (0, (3, 3))\n",
    "linestyle2 = (0, (5, 3))\n",
    "linewidth = 2\n",
    "\n",
    "# Sorting values for plotting\n",
    "sorted_indices = np.argsort(x_test.squeeze())\n",
    "x_test_sorted = x_test[sorted_indices]/365\n",
    "y_test_sorted = y_test[sorted_indices]\n",
    "\n",
    "plt.plot(x_test_sorted, y_test_sorted, \"o\", markersize = 0.1, color = dot_color)\n",
    "plt.plot(x_test_sorted, regular_bounds[0][sorted_indices], color = unregulated_color, linestyle = linestyle1, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, regular_bounds[1][sorted_indices], color = unregulated_color, linestyle = linestyle1, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, robust_bounds[0][sorted_indices], color = robust_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, robust_bounds[1][sorted_indices], color = robust_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, strict_bounds[0][sorted_indices], color = strict_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, strict_bounds[1][sorted_indices], color = strict_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.ylim((5,20))\n",
    "plt.xlabel(\"Age (Years)\")\n",
    "plt.ylabel(\"Hemoglobin Level (g/dL)\")\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=unregulated_color, label=\"No Penalty\", linestyle = linestyle1),\n",
    "    plt.Line2D([0], [0], color=robust_color, label=\"50% Penalty\", linestyle = linestyle2),\n",
    "    plt.Line2D([0], [0], color=strict_color, label=\"60% Penalty\", linestyle = linestyle2)\n",
    "]\n",
    "\n",
    "plt.legend(handles = legend_handles, loc = \"upper left\")\n",
    "plt.title(\"95% Intervals for Healthy Hemoglobin Levels (Female Children)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Penalty - Male Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "male_df = hemoglobin[hemoglobin[\"SEX\"]==\"M\"][[\"AGE\", \"VAL\"]]\n",
    "male_df = male_df.to_numpy()\n",
    "\n",
    "# training_sample_indices = random.sample(range(1, len(male_df)), int(10000))\n",
    "x_train = male_df[training_sample_indices, 0]\n",
    "y_train = male_df[training_sample_indices, 1]\n",
    "\n",
    "# validation_sample_indices = random.sample(range(1, len(male_df)), int(10000))\n",
    "x_val = male_df[validation_sample_indices, 0]\n",
    "y_val = male_df[validation_sample_indices, 1]\n",
    "\n",
    "# testing_sample_indices = random.sample(range(1, len(male_df)), int(10000))\n",
    "x_test = male_df[testing_sample_indices, 0]\n",
    "y_test = male_df[testing_sample_indices, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_test, y_test, \"o\", markersize = 0.1, color = \"cornflowerblue\")\n",
    "plt.ylim(5, 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train).unsqueeze(1)\n",
    "x_val = torch.tensor(x_val).unsqueeze(1)\n",
    "x_test = torch.tensor(x_test).unsqueeze(1)\n",
    "\n",
    "y_train = torch.tensor(y_train).unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_scaler, y_scaler = StandardScaler(), StandardScaler()\n",
    "\n",
    "x_train_scaled = torch.tensor(x_scaler.fit_transform(x_train), dtype = torch.float32)\n",
    "x_val_scaled = torch.tensor(x_scaler.transform(x_val), dtype = torch.float32)\n",
    "x_test_scaled = torch.tensor(x_scaler.transform(x_test), dtype = torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(y_scaler.fit_transform(y_train), dtype = torch.float32)\n",
    "y_val_scaled = torch.tensor(y_scaler.transform(y_val), dtype = torch.float32)\n",
    "y_test_scaled = torch.tensor(y_scaler.transform(y_test), dtype = torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = NormalNAMLSS(1)\n",
    "nam.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled)\n",
    "mu_train, sigma_train = nam.predict(x_train_scaled)\n",
    "normal_dist = dist.Normal(mu_train, sigma_train)\n",
    "log_likelihood = normal_dist.log_prob(y_train_scaled)\n",
    "\n",
    "robust_quantile_value = torch.quantile(log_likelihood, 0.50) # smaller quantile\n",
    "strict_quantile_value = torch.quantile(log_likelihood, 0.60) # larger quantile\n",
    "\n",
    "robust_c = torch.log(torch.exp(-robust_quantile_value) - 1)\n",
    "strict_c = torch.log(torch.exp(-strict_quantile_value) - 1)\n",
    "\n",
    "robust_c = torch.log(torch.exp(-robust_quantile_value) - 1)\n",
    "strict_c = torch.log(torch.exp(-strict_quantile_value) - 1)\n",
    "\n",
    "robust_nam = NormalNAMLSS(1)\n",
    "robust_nam.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, robustness_factor = torch.tensor(robust_c))\n",
    "\n",
    "strict_nam = NormalNAMLSS(1)\n",
    "strict_nam .fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, robustness_factor = torch.tensor(strict_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting parameters based on scaled values\n",
    "mu, sigma = nam.predict(x_test_scaled)\n",
    "robust_mu, robust_sigma = robust_nam.predict(x_test_scaled)\n",
    "strict_mu, strict_sigma = strict_nam.predict(x_test_scaled)\n",
    "\n",
    "# Rescaling the predictions for plotting\n",
    "mu = mu * y_scaler.scale_ + y_scaler.mean_\n",
    "robust_mu = robust_mu * y_scaler.scale_ + y_scaler.mean_\n",
    "strict_mu = strict_mu * y_scaler.scale_ + y_scaler.mean_\n",
    "\n",
    "sigma = sigma * y_scaler.scale_\n",
    "robust_sigma = robust_sigma * y_scaler.scale_\n",
    "strict_sigma = strict_sigma * y_scaler.scale_\n",
    "\n",
    "# Calculating 95% reference interval bounds\n",
    "regular_bounds = [mu - 1.96 * sigma, mu + 1.96 * sigma]\n",
    "robust_bounds = [robust_mu - 1.96 * robust_sigma, robust_mu + 1.96 * robust_sigma]\n",
    "strict_bounds = [strict_mu - 1.96 * strict_sigma, strict_mu + 1.96 * strict_sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregulated_color = \"forestgreen\"\n",
    "robust_color = \"indigo\"\n",
    "strict_color = \"crimson\"\n",
    "dot_color = \"cornflowerblue\"\n",
    "\n",
    "linestyle1 = (0, (3, 3))\n",
    "linestyle2 = (0, (5, 3))\n",
    "linewidth = 2\n",
    "\n",
    "# Sorting values for plotting\n",
    "sorted_indices = np.argsort(x_test.squeeze())\n",
    "x_test_sorted = x_test[sorted_indices]/365\n",
    "y_test_sorted = y_test[sorted_indices]\n",
    "\n",
    "plt.plot(x_test_sorted, y_test_sorted, \"o\", markersize = 0.1, color = dot_color)\n",
    "plt.plot(x_test_sorted, regular_bounds[0][sorted_indices], color = unregulated_color, linestyle = linestyle1, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, regular_bounds[1][sorted_indices], color = unregulated_color, linestyle = linestyle1, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, robust_bounds[0][sorted_indices], color = robust_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, robust_bounds[1][sorted_indices], color = robust_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, strict_bounds[0][sorted_indices], color = strict_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.plot(x_test_sorted, strict_bounds[1][sorted_indices], color = strict_color, linestyle = linestyle2, linewidth = linewidth)\n",
    "plt.ylim((5,20))\n",
    "plt.xlabel(\"Age (Years)\")\n",
    "plt.ylabel(\"Hemoglobin Level (g/dL)\")\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=unregulated_color, label=\"No Penalty\", linestyle = linestyle1),\n",
    "    plt.Line2D([0], [0], color=robust_color, label=\"50% Penalty\", linestyle = linestyle2),\n",
    "    plt.Line2D([0], [0], color=strict_color, label=\"60% Penalty\", linestyle = linestyle2)\n",
    "]\n",
    "\n",
    "plt.legend(handles = legend_handles, loc = \"upper left\")\n",
    "plt.title(\"95% Intervals for Healthy Hemoglobin Level (Male Children)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
